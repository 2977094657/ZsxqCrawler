#!/usr/bin/env python3
"""
çŸ¥è¯†æ˜Ÿçƒäº¤äº’å¼æ•°æ®é‡‡é›†å™¨
æ”¯æŒå¤šç§çˆ¬å–æ¨¡å¼ï¼Œå¢å¼ºåæ£€æµ‹æœºåˆ¶
"""

import requests
import time
import random
import json
from typing import Dict, Any, Optional, List
from zsxq_database import ZSXQDatabase
from zsxq_file_downloader import ZSXQFileDownloader
import os
try:
    import tomllib
except ImportError:
    try:
        import tomli as tomllib
    except ImportError:
        print("âš ï¸ éœ€è¦å®‰è£…tomliåº“æ¥è§£æTOMLé…ç½®æ–‡ä»¶")
        print("ğŸ’¡ è¯·è¿è¡Œ: pip install tomli")
        tomllib = None


class ZSXQInteractiveCrawler:
    """çŸ¥è¯†æ˜Ÿçƒäº¤äº’å¼æ•°æ®é‡‡é›†å™¨"""
    
    def __init__(self, cookie: str, group_id: str, db_path: str = "zsxq_interactive.db"):
        self.cookie = self.clean_cookie(cookie)
        self.group_id = group_id
        self.db = ZSXQDatabase(db_path)
        self.session = requests.Session()
        
        # æ–‡ä»¶ä¸‹è½½å™¨ï¼ˆæ‡’åŠ è½½ï¼‰
        self.file_downloader = None
        
        # åŸºç¡€APIé…ç½®
        self.base_url = "https://api.zsxq.com"
        self.api_endpoint = f"/v2/groups/{group_id}/topics"
        
        # åæ£€æµ‹é…ç½®
        self.request_count = 0
        self.page_count = 0  # æˆåŠŸå¤„ç†çš„é¡µé¢æ•°
        self.last_request_time = 0
        self.min_delay = 2.0  # æœ€å°å»¶è¿Ÿ
        self.max_delay = 5.0  # æœ€å¤§å»¶è¿Ÿ
        self.long_delay_interval = 15  # æ¯15ä¸ªé¡µé¢è¿›è¡Œé•¿å»¶è¿Ÿ
        self.debug_mode = False  # è°ƒè¯•æ¨¡å¼
        self.timestamp_offset_ms = 1  # æ—¶é—´æˆ³å‡å»çš„æ¯«ç§’æ•°
        
        print(f"ğŸš€ çŸ¥è¯†æ˜Ÿçƒäº¤äº’å¼é‡‡é›†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“Š ç›®æ ‡ç¾¤ç»„: {group_id}")
        print(f"ğŸ’¾ æ•°æ®åº“: {db_path}")
        
        # æ˜¾ç¤ºå½“å‰æ•°æ®åº“çŠ¶æ€
        self.show_database_status()
    
    def clean_cookie(self, cookie: str) -> str:
        """æ¸…ç†Cookieå­—ç¬¦ä¸²ï¼Œå»é™¤ä¸åˆæ³•å­—ç¬¦
        
        Args:
            cookie (str): åŸå§‹Cookieå­—ç¬¦ä¸²
        
        Returns:
            str: æ¸…ç†åçš„Cookieå­—ç¬¦ä¸²
        """
        try:
            # å¦‚æœæ˜¯bytesç±»å‹ï¼Œå…ˆè§£ç 
            if isinstance(cookie, bytes):
                cookie = cookie.decode('utf-8')
            
            # å»é™¤å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œç¬¦
            cookie = cookie.strip()
            
            # å¦‚æœæœ‰å¤šè¡Œï¼Œåªå–ç¬¬ä¸€è¡Œ
            if '\n' in cookie:
                cookie = cookie.split('\n')[0]
            
            # å»é™¤æœ«å°¾çš„åæ–œæ 
            cookie = cookie.rstrip('\\')
            
            # å»é™¤å¯èƒ½çš„å‰ç¼€bå’Œå¼•å·
            if cookie.startswith("b'") and cookie.endswith("'"):
                cookie = cookie[2:-1]
            elif cookie.startswith('b"') and cookie.endswith('"'):
                cookie = cookie[2:-1]
            elif cookie.startswith("'") and cookie.endswith("'"):
                cookie = cookie[1:-1]
            elif cookie.startswith('"') and cookie.endswith('"'):
                cookie = cookie[1:-1]
            
            # å¤„ç†è½¬ä¹‰å­—ç¬¦
            cookie = cookie.replace('\\n', '')
            cookie = cookie.replace('\\"', '"')
            cookie = cookie.replace("\\'", "'")
            
            # ç¡®ä¿åˆ†å·åæœ‰ç©ºæ ¼
            cookie = '; '.join(part.strip() for part in cookie.split(';'))
            
            return cookie
        except Exception as e:
            print(f"Cookieæ¸…ç†å¤±è´¥: {e}")
            return cookie  # è¿”å›åŸå§‹å€¼
    
    def get_file_downloader(self):
        """è·å–æ–‡ä»¶ä¸‹è½½å™¨ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self.file_downloader is None:
            self.file_downloader = ZSXQFileDownloader(self.cookie, self.group_id)
        return self.file_downloader
    
    def show_database_status(self):
        """æ˜¾ç¤ºæ•°æ®åº“å½“å‰çŠ¶æ€"""
        stats = self.db.get_database_stats()
        total_topics = stats.get('topics', 0)
        total_users = stats.get('users', 0)
        total_comments = stats.get('comments', 0)
        
        print(f"\nğŸ“Š å½“å‰æ•°æ®åº“çŠ¶æ€:")
        print(f"   è¯é¢˜: {total_topics}, ç”¨æˆ·: {total_users}, è¯„è®º: {total_comments}")
        
        # æ˜¾ç¤ºæ—¶é—´æˆ³èŒƒå›´ä¿¡æ¯
        if total_topics > 0:
            timestamp_info = self.db.get_timestamp_range_info()
            if timestamp_info['has_data']:
                print(f"   æ—¶é—´èŒƒå›´: {timestamp_info['oldest_timestamp']} ~ {timestamp_info['newest_timestamp']}")
            else:
                print(f"   âš ï¸ æ—¶é—´æˆ³æ•°æ®ä¸å®Œæ•´")
    
    def get_stealth_headers(self) -> Dict[str, str]:
        """è·å–éšè”½æ€§æ›´å¼ºçš„è¯·æ±‚å¤´"""
        # æ›´å¤šæ ·åŒ–çš„User-Agentæ± 
        user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
        ]
        
        # åŸºç¡€å¤´éƒ¨
        headers = {
            "Accept": "application/json, text/plain, */*",
            "Accept-Encoding": "gzip, deflate, br, zstd",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8,zh-TW;q=0.7",
            "Cache-Control": "no-cache",
            "Cookie": self.cookie,
            "Origin": "https://wx.zsxq.com",
            "Pragma": "no-cache",
            "Priority": "u=1, i",
            "Referer": "https://wx.zsxq.com/",
            "Sec-Ch-Ua": '"Google Chrome";v="137", "Chromium";v="137", "Not/A)Brand";v="24"',
            "Sec-Ch-Ua-Mobile": "?0",
            "Sec-Ch-Ua-Platform": '"Windows"',
            "Sec-Fetch-Dest": "empty",
            "Sec-Fetch-Mode": "cors",
            "Sec-Fetch-Site": "same-site",
            "User-Agent": random.choice(user_agents),
            "X-Aduid": "a3be07cd6-dd67-3912-0093-862d844e7fe",
            "X-Request-Id": f"dcc5cb6ab-1bc3-8273-cc26-{random.randint(100000000000, 999999999999)}",
            "X-Signature": "733fd672ddf6d4e367730d9622cdd1e28a4b6203",
            "X-Timestamp": str(int(time.time())),
            "X-Version": "2.77.0"
        }
        
        # éšæœºæ·»åŠ å¯é€‰å¤´éƒ¨
        optional_headers = {
            "X-Requested-With": "XMLHttpRequest",
            "Sec-GPC": "1",
            "Upgrade-Insecure-Requests": "1"
        }
        
        for key, value in optional_headers.items():
            if random.random() > 0.4:  # 60%æ¦‚ç‡æ·»åŠ 
                headers[key] = value
        
        return headers
    
    def smart_delay(self, is_historical: bool = False):
        """æ™ºèƒ½å»¶è¿Ÿæœºåˆ¶ - æ¨¡æ‹Ÿäººç±»è¡Œä¸ºï¼ˆä»…åŸºç¡€å»¶è¿Ÿï¼‰"""
        self.request_count += 1
        
        # åŸºç¡€å»¶è¿Ÿæ—¶é—´
        if is_historical:
            delay = random.uniform(self.min_delay + 1.0, self.max_delay + 2.0)  # å†å²çˆ¬å–ç¨é•¿
        else:
            delay = random.uniform(self.min_delay, self.max_delay)
        
        time.sleep(delay)
        self.last_request_time = time.time()
        
        # è°ƒè¯•ä¿¡æ¯
        if self.debug_mode:
            print(f"   â±ï¸ å»¶è¿Ÿ: {delay:.2f}ç§’ (è¯·æ±‚#{self.request_count})")
    
    def check_page_long_delay(self):
        """æ£€æŸ¥é¡µé¢çº§é•¿ä¼‘çœ ï¼šæ¯15ä¸ªé¡µé¢è¿›è¡Œé•¿ä¼‘çœ """
        self.page_count += 1
        
        if self.page_count % self.long_delay_interval == 0:
            import datetime
            
            long_delay = random.uniform(180, 300)  # 3-5åˆ†é’Ÿé•¿ä¼‘çœ 
            start_time = datetime.datetime.now()
            end_time = start_time + datetime.timedelta(seconds=long_delay)
            
            print(f"ğŸ›Œ é•¿ä¼‘çœ å¼€å§‹: {long_delay:.1f}ç§’ ({long_delay/60:.1f}åˆ†é’Ÿ)")
            print(f"   å·²å®Œæˆ {self.page_count} ä¸ªé¡µé¢ï¼Œè¿›å…¥é•¿ä¼‘çœ æ¨¡å¼...")
            print(f"   â° å¼€å§‹æ—¶é—´: {start_time.strftime('%H:%M:%S')}")
            print(f"   ğŸ• é¢„è®¡æ¢å¤: {end_time.strftime('%H:%M:%S')}")
            
            time.sleep(long_delay)
            
            actual_end_time = datetime.datetime.now()
            print(f"ğŸ˜´ é•¿ä¼‘çœ ç»“æŸï¼Œç»§ç»­çˆ¬å–...")
            print(f"   ğŸ• å®é™…ç»“æŸ: {actual_end_time.strftime('%H:%M:%S')}")
            
            # è°ƒè¯•ä¿¡æ¯
            if self.debug_mode:
                actual_duration = (actual_end_time - start_time).total_seconds()
                print(f"   ğŸ’¤ é•¿ä¼‘çœ å®Œæˆ: é¢„è®¡{long_delay:.1f}ç§’ï¼Œå®é™…{actual_duration:.1f}ç§’ (é¡µé¢#{self.page_count})")
    
    def fetch_topics_safe(self, scope: str = "all", count: int = 20, 
                         end_time: Optional[str] = None, is_historical: bool = False) -> Optional[Dict[str, Any]]:
        """å®‰å…¨çš„è¯é¢˜è·å–æ–¹æ³•"""
        
        # æ™ºèƒ½å»¶è¿Ÿ
        self.smart_delay(is_historical)
        
        url = f"{self.base_url}{self.api_endpoint}"
        headers = self.get_stealth_headers()
        
        # æ„å»ºå‚æ•°
        params = {
            "scope": scope,
            "count": str(count)
        }
        
        if end_time:
            params["end_time"] = end_time
        
        # ä¸æ·»åŠ é¢å¤–å‚æ•°ï¼Œä¿æŒä¸å®˜ç½‘è¯·æ±‚ä¸€è‡´
        # random_params = {
        #     "_t": str(int(time.time() * 1000)),
        #     "v": "1.0",
        #     "_r": str(random.randint(1000, 9999))
        # }
        # 
        # for key, value in random_params.items():
        #     if random.random() > 0.3:  # 70%æ¦‚ç‡æ·»åŠ 
        #         params[key] = value
        
        # æ„é€ å®Œæ•´URLç”¨äºæ˜¾ç¤º
        from urllib.parse import urlencode
        full_url = f"{url}?{urlencode(params)}"
        
        print(f"ğŸŒ å®‰å…¨è¯·æ±‚ #{self.request_count}")
        print(f"   ğŸ¯ å‚æ•°: scope={scope}, count={count}")
        if end_time:
            print(f"   ğŸ“… æ—¶é—´: {end_time}")
        print(f"   ğŸ”— å®Œæ•´é“¾æ¥: {full_url}")
        
        # è°ƒè¯•æ¨¡å¼è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        if self.debug_mode:
            print(f"   ğŸ” è°ƒè¯•æ¨¡å¼:")
            print(f"   ğŸ“ åŸºç¡€URL: {url}")
            print(f"   ğŸ“Š æ‰€æœ‰å‚æ•°: {params}")
            print(f"   ğŸ”§ è¯·æ±‚å¤´: {json.dumps(headers, ensure_ascii=False, indent=4)}")
            print(f"   ğŸª Cookieé•¿åº¦: {len(self.cookie)}å­—ç¬¦")
            print(f"   â° å½“å‰æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            response = self.session.get(
                url, 
                headers=headers, 
                params=params, 
                timeout=45,  # å¢åŠ è¶…æ—¶æ—¶é—´
                allow_redirects=True
            )
            
            print(f"   ğŸ“Š çŠ¶æ€: {response.status_code}, å¤§å°: {len(response.content)}B")
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    if data.get('succeeded'):
                        topics = data.get('resp_data', {}).get('topics', [])
                        print(f"   âœ… è·å–æˆåŠŸ: {len(topics)}ä¸ªè¯é¢˜")
                        return data
                    else:
                        print(f"   âŒ APIå¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                        print(f"   ğŸ“‹ å®Œæ•´å“åº”: {json.dumps(data, ensure_ascii=False, indent=2)}")
                        return None
                except json.JSONDecodeError as e:
                    print(f"   âŒ JSONè§£æå¤±è´¥: {e}")
                    print(f"   ğŸ“„ å“åº”å†…å®¹: {response.text[:500]}...")
                    print(f"   ğŸ“‹ å“åº”å¤´: {dict(response.headers)}")
                    return None
            else:
                print(f"   âŒ HTTPé”™è¯¯: {response.status_code}")
                print(f"   ğŸ“„ å“åº”å†…å®¹: {response.text}")
                print(f"   ğŸ“‹ å“åº”å¤´: {dict(response.headers)}")
                if response.status_code == 429:
                    print("   ğŸš¨ è§¦å‘é¢‘ç‡é™åˆ¶ï¼Œå»ºè®®å¢åŠ å»¶è¿Ÿæ—¶é—´")
                elif response.status_code == 403:
                    print("   ğŸš¨ è®¿é—®è¢«æ‹’ç»ï¼Œå¯èƒ½éœ€è¦æ›´æ–°Cookieæˆ–åæ£€æµ‹ç­–ç•¥")
                elif response.status_code == 401:
                    print("   ğŸš¨ è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥Cookieæ˜¯å¦è¿‡æœŸ")
                return None
                
        except requests.exceptions.Timeout as e:
            print(f"   âŒ è¯·æ±‚è¶…æ—¶: {e}")
            print(f"   ğŸ”§ å»ºè®®: å¢åŠ è¶…æ—¶æ—¶é—´æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥")
            return None
        except requests.exceptions.ConnectionError as e:
            print(f"   âŒ è¿æ¥é”™è¯¯: {e}")
            print(f"   ğŸ”§ å»ºè®®: æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–DNSè®¾ç½®")
            return None
        except requests.exceptions.HTTPError as e:
            print(f"   âŒ HTTPåè®®é”™è¯¯: {e}")
            return None
        except requests.exceptions.RequestException as e:
            print(f"   âŒ è¯·æ±‚å¼‚å¸¸: {e}")
            print(f"   ğŸ”§ å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            return None
    
    def store_batch_data(self, data: Dict[str, Any]) -> Dict[str, int]:
        """æ‰¹é‡å­˜å‚¨æ•°æ®åˆ°æ•°æ®åº“"""
        if not data or not data.get('succeeded'):
            return {'new_topics': 0, 'updated_topics': 0, 'errors': 0}
        
        topics = data.get('resp_data', {}).get('topics', [])
        if not topics:
            return {'new_topics': 0, 'updated_topics': 0, 'errors': 0}
        
        stats = {'new_topics': 0, 'updated_topics': 0, 'errors': 0}
        
        for topic_data in topics:
            try:
                topic_id = topic_data.get('topic_id')
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                self.db.cursor.execute('SELECT topic_id FROM topics WHERE topic_id = ?', (topic_id,))
                exists = self.db.cursor.fetchone()
                
                # å¯¼å…¥æ•°æ®
                self.db.import_topic_data(topic_data)
                
                if exists:
                    stats['updated_topics'] += 1
                else:
                    stats['new_topics'] += 1
                
            except Exception as e:
                stats['errors'] += 1
                print(f"   âš ï¸ è¯é¢˜å¯¼å…¥å¤±è´¥: {e}")
        
        # æäº¤äº‹åŠ¡
        self.db.conn.commit()
        return stats
    
    def crawl_latest(self, count: int = 20) -> Dict[str, int]:
        """çˆ¬å–æœ€æ–°è¯é¢˜"""
        print(f"\nğŸ†• çˆ¬å–æœ€æ–° {count} ä¸ªè¯é¢˜...")
        
        data = self.fetch_topics_safe(scope="all", count=count)
        if data:
            stats = self.store_batch_data(data)
            print(f"ğŸ’¾ å­˜å‚¨ç»“æœ: æ–°å¢{stats['new_topics']}, æ›´æ–°{stats['updated_topics']}")
            return stats
        else:
            print("âŒ è·å–å¤±è´¥")
            return {'new_topics': 0, 'updated_topics': 0, 'errors': 1}
    
    def crawl_historical(self, pages: int = 10, per_page: int = 20) -> Dict[str, int]:
        """çˆ¬å–å†å²æ•°æ®"""
        print(f"\nğŸ“š çˆ¬å–å†å²æ•°æ®: {pages}é¡µ x {per_page}æ¡/é¡µ")
        
        total_stats = {'new_topics': 0, 'updated_topics': 0, 'errors': 0, 'pages': 0}
        end_time = None
        completed_pages = 0
        max_retries_per_page = 10  # æ¯é¡µæœ€å¤§é‡è¯•æ¬¡æ•°
        
        while completed_pages < pages:
            current_page = completed_pages + 1
            print(f"\nğŸ“„ é¡µé¢ {current_page}/{pages}")
            retry_count = 0
            
            # é‡è¯•å½“å‰é¡µç›´åˆ°æˆåŠŸæˆ–è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
            while retry_count < max_retries_per_page:
                if retry_count > 0:
                    print(f"   ğŸ”„ ç¬¬{retry_count}æ¬¡é‡è¯•")
                
                # è·å–æ•°æ®
                if current_page == 1:
                    data = self.fetch_topics_safe(scope="all", count=per_page, is_historical=True)
                else:
                    data = self.fetch_topics_safe(scope="all", count=per_page, 
                                                end_time=end_time, is_historical=True)
                
                if data:
                    # æˆåŠŸè·å–æ•°æ®
                    topics = data.get('resp_data', {}).get('topics', [])
                    if not topics:
                        print(f"   ğŸ“­ æ— æ›´å¤šæ•°æ®ï¼Œåœæ­¢çˆ¬å–")
                        return total_stats
                    
                    # å­˜å‚¨æ•°æ®
                    page_stats = self.store_batch_data(data)
                    print(f"   ğŸ’¾ é¡µé¢å­˜å‚¨: æ–°å¢{page_stats['new_topics']}, æ›´æ–°{page_stats['updated_topics']}")
                    
                    # ç´¯è®¡ç»Ÿè®¡
                    total_stats['new_topics'] += page_stats['new_topics']
                    total_stats['updated_topics'] += page_stats['updated_topics']
                    total_stats['errors'] += page_stats['errors']
                    total_stats['pages'] += 1
                    completed_pages += 1
                    
                    # è°ƒè¯•ï¼šæ˜¾ç¤ºæ‰€æœ‰è¯é¢˜çš„æ—¶é—´æˆ³
                    print(f"   ğŸ” è°ƒè¯•ä¿¡æ¯:")
                    print(f"   ğŸ“Š æœ¬é¡µè·å–åˆ° {len(topics)} ä¸ªè¯é¢˜")
                    for i, topic in enumerate(topics):
                        topic_time = topic.get('create_time', 'N/A')
                        topic_title = topic.get('title', 'æ— æ ‡é¢˜')[:30]
                        print(f"   {i+1:2d}. {topic_time} - {topic_title}")
                    
                    # å‡†å¤‡ä¸‹ä¸€é¡µçš„æ—¶é—´æˆ³
                    if topics:
                        original_time = topics[-1].get('create_time')
                        try:
                            from datetime import datetime, timedelta
                            dt = datetime.fromisoformat(original_time.replace('+0800', '+08:00'))
                            dt = dt - timedelta(milliseconds=self.timestamp_offset_ms)
                            end_time = dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + '+0800'
                            print(f"   ğŸ“… åŸå§‹æ—¶é—´æˆ³: {original_time}")
                            print(f"   â­ï¸ ä¸‹ä¸€é¡µæ—¶é—´æˆ³: {end_time} (å‡å»{self.timestamp_offset_ms}æ¯«ç§’)")
                        except Exception as e:
                            end_time = original_time
                            print(f"   âš ï¸ æ—¶é—´æˆ³è°ƒæ•´å¤±è´¥: {e}")
                            print(f"   â­ï¸ ä¸‹ä¸€é¡µæ—¶é—´æˆ³: {end_time} (æœªè°ƒæ•´)")
                    
                    # æ£€æŸ¥æ˜¯å¦å·²çˆ¬å®Œ
                    if len(topics) < per_page:
                        print(f"   ğŸ“­ å·²çˆ¬å–å®Œæ¯• (è¿”å›{len(topics)}æ¡)")
                        return total_stats
                    
                    # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    self.check_page_long_delay()  # é¡µé¢æˆåŠŸå¤„ç†åè¿›è¡Œé•¿ä¼‘çœ æ£€æŸ¥
                    break
                else:
                    # å¤±è´¥ï¼Œå¢åŠ é‡è¯•è®¡æ•°å’Œé”™è¯¯è®¡æ•°
                    retry_count += 1
                    total_stats['errors'] += 1
                    print(f"   âŒ é¡µé¢ {current_page} è·å–å¤±è´¥ (é‡è¯•{retry_count}/{max_retries_per_page})")
                    
                    # è°ƒæ•´æ—¶é—´æˆ³ç”¨äºé‡è¯•
                    if end_time:
                        try:
                            from datetime import datetime, timedelta
                            dt = datetime.fromisoformat(end_time.replace('+0800', '+08:00'))
                            dt = dt - timedelta(milliseconds=self.timestamp_offset_ms)
                            end_time = dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + '+0800'
                            print(f"   ğŸ”„ è°ƒæ•´æ—¶é—´æˆ³: {end_time} (å†æ¬¡å‡å»{self.timestamp_offset_ms}æ¯«ç§’)")
                        except Exception as e:
                            print(f"   âš ï¸ æ—¶é—´æˆ³è°ƒæ•´å¤±è´¥: {e}")
            
            # å¦‚æœé‡è¯•æ¬¡æ•°ç”¨å®Œä»ç„¶å¤±è´¥
            if retry_count >= max_retries_per_page:
                print(f"   ğŸš« é¡µé¢ {current_page} è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè·³è¿‡æ­¤é¡µ")
                # å¦‚æœæœ‰æ—¶é—´æˆ³ï¼Œå°è¯•å¤§å¹…åº¦è°ƒæ•´è·³è¿‡é—®é¢˜åŒºåŸŸ
                if end_time:
                    try:
                        from datetime import datetime, timedelta
                        dt = datetime.fromisoformat(end_time.replace('+0800', '+08:00'))
                        # å¤§å¹…åº¦è·³è¿‡ï¼Œå‡å»1å°æ—¶
                        dt = dt - timedelta(hours=1)
                        end_time = dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + '+0800'
                        print(f"   â° å¤§å¹…åº¦è·³è¿‡æ—¶é—´æ®µ: {end_time} (å‡å»1å°æ—¶)")
                    except Exception as e:
                        print(f"   âš ï¸ å¤§å¹…åº¦æ—¶é—´æˆ³è°ƒæ•´å¤±è´¥: {e}")
                completed_pages += 1  # è·³è¿‡è¿™ä¸€é¡µ
        
        print(f"\nğŸ å†å²çˆ¬å–å®Œæˆ:")
        print(f"   ğŸ“„ æˆåŠŸé¡µæ•°: {total_stats['pages']}")
        print(f"   âœ… æ–°å¢è¯é¢˜: {total_stats['new_topics']}")
        print(f"   ğŸ”„ æ›´æ–°è¯é¢˜: {total_stats['updated_topics']}")
        if total_stats['errors'] > 0:
            print(f"   âŒ æ€»é”™è¯¯æ•°: {total_stats['errors']}")
        
        return total_stats
    
    def crawl_all_historical(self, per_page: int = 20) -> Dict[str, int]:
        """è·å–æ‰€æœ‰å†å²æ•°æ®ï¼šæ— é™çˆ¬å–ç›´åˆ°æ²¡æœ‰æ•°æ®ï¼ˆä½¿ç”¨å¢é‡çˆ¬å–é€»è¾‘ï¼‰"""
        print(f"\nğŸŒŠ è·å–æ‰€æœ‰å†å²æ•°æ®æ¨¡å¼ (æ¯é¡µ{per_page}æ¡)")
        print(f"âš ï¸ è­¦å‘Šï¼šæ­¤æ¨¡å¼å°†æŒç»­çˆ¬å–ç›´åˆ°æ²¡æœ‰æ•°æ®ï¼Œå¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´")
        
        # æ£€æŸ¥æ•°æ®åº“çŠ¶æ€ï¼Œå¦‚æœæœ‰æ•°æ®åˆ™ä½¿ç”¨å¢é‡çˆ¬å–é€»è¾‘
        timestamp_info = self.db.get_timestamp_range_info()
        start_end_time = None
        
        if timestamp_info['has_data']:
            oldest_timestamp = timestamp_info['oldest_timestamp']
            total_existing = timestamp_info['total_topics']
            
            print(f"ğŸ“Š æ•°æ®åº“ç°çŠ¶:")
            print(f"   ç°æœ‰è¯é¢˜æ•°: {total_existing}")
            print(f"   æœ€è€æ—¶é—´æˆ³: {oldest_timestamp}")
            print(f"   æœ€æ–°æ—¶é—´æˆ³: {timestamp_info['newest_timestamp']}")
            print(f"ğŸ¯ å°†ä»æœ€è€æ—¶é—´æˆ³å¼€å§‹ç»§ç»­å‘å†å²çˆ¬å–ï¼ˆå¢é‡æ¨¡å¼ï¼‰...")
            
            # å‡†å¤‡å¢é‡çˆ¬å–çš„èµ·å§‹æ—¶é—´æˆ³
            try:
                from datetime import datetime, timedelta
                dt = datetime.fromisoformat(oldest_timestamp.replace('+0800', '+08:00'))
                dt = dt - timedelta(milliseconds=self.timestamp_offset_ms)
                start_end_time = dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + '+0800'
                print(f"ğŸš€ å¢é‡çˆ¬å–èµ·å§‹æ—¶é—´æˆ³: {start_end_time}")
            except Exception as e:
                print(f"âš ï¸ æ—¶é—´æˆ³å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸæ—¶é—´æˆ³: {e}")
                start_end_time = oldest_timestamp
        else:
            print(f"ğŸ“Š æ•°æ®åº“ä¸ºç©ºï¼Œå°†ä»æœ€æ–°æ•°æ®å¼€å§‹çˆ¬å–")
        
        # ç”¨æˆ·ç¡®è®¤
        confirm = input("ç¡®è®¤å¼€å§‹æ— é™çˆ¬å–ï¼Ÿ(y/N): ").lower().strip()
        if confirm != 'y':
            print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return {'new_topics': 0, 'updated_topics': 0, 'errors': 0, 'pages': 0}
        
        print(f"ğŸš€ å¼€å§‹æ— é™å†å²çˆ¬å–...")
        
        total_stats = {'new_topics': 0, 'updated_topics': 0, 'errors': 0, 'pages': 0}
        end_time = start_end_time  # ä½¿ç”¨å¢é‡çˆ¬å–çš„èµ·å§‹æ—¶é—´æˆ³
        current_page = 0
        max_retries_per_page = 10
        consecutive_empty_pages = 0  # è¿ç»­ç©ºé¡µé¢è®¡æ•°
        max_consecutive_empty = 3   # æœ€å¤§è¿ç»­ç©ºé¡µé¢æ•°
        
        while True:
            current_page += 1
            print(f"\nğŸ“„ é¡µé¢ {current_page}")
            retry_count = 0
            page_success = False
            
            # é‡è¯•å½“å‰é¡µç›´åˆ°æˆåŠŸæˆ–è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
            while retry_count < max_retries_per_page:
                if retry_count > 0:
                    print(f"   ğŸ”„ ç¬¬{retry_count}æ¬¡é‡è¯•")
                
                # è·å–æ•°æ® - æ ¹æ®æ˜¯å¦æœ‰èµ·å§‹æ—¶é—´æˆ³å†³å®šè¯·æ±‚æ–¹å¼
                if current_page == 1 and start_end_time is None:
                    # æ•°æ®åº“ä¸ºç©ºï¼Œä»æœ€æ–°å¼€å§‹
                    data = self.fetch_topics_safe(scope="all", count=per_page, is_historical=True)
                else:
                    # æœ‰æ•°æ®æˆ–åç»­é¡µé¢ï¼Œä½¿ç”¨ end_time å‚æ•°
                    data = self.fetch_topics_safe(scope="all", count=per_page, 
                                                end_time=end_time, is_historical=True)
                
                if data:
                    # æˆåŠŸè·å–æ•°æ®
                    topics = data.get('resp_data', {}).get('topics', [])
                    
                    if not topics:
                        consecutive_empty_pages += 1
                        print(f"   ğŸ“­ ç¬¬{consecutive_empty_pages}ä¸ªç©ºé¡µé¢")
                        
                        if consecutive_empty_pages >= max_consecutive_empty:
                            print(f"   ğŸ è¿ç»­{max_consecutive_empty}ä¸ªç©ºé¡µé¢ï¼Œæ‰€æœ‰å†å²æ•°æ®çˆ¬å–å®Œæˆ")
                            print(f"\nğŸ‰ æ— é™çˆ¬å–å®Œæˆæ€»ç»“:")
                            print(f"   ğŸ“„ æ€»é¡µæ•°: {total_stats['pages']}")
                            print(f"   âœ… æ–°å¢è¯é¢˜: {total_stats['new_topics']}")
                            print(f"   ğŸ”„ æ›´æ–°è¯é¢˜: {total_stats['updated_topics']}")
                            if total_stats['errors'] > 0:
                                print(f"   âŒ æ€»é”™è¯¯æ•°: {total_stats['errors']}")
                            
                            # æ˜¾ç¤ºæœ€ç»ˆæ•°æ®åº“çŠ¶æ€
                            final_db_stats = self.db.get_timestamp_range_info()
                            if final_db_stats['has_data']:
                                print(f"\nğŸ“Š æœ€ç»ˆæ•°æ®åº“çŠ¶æ€:")
                                print(f"   è¯é¢˜æ€»æ•°: {final_db_stats['total_topics']}")
                                if timestamp_info['has_data']:
                                    print(f"   æ–°å¢è¯é¢˜: {final_db_stats['total_topics'] - timestamp_info['total_topics']}")
                                print(f"   æ—¶é—´èŒƒå›´: {final_db_stats['oldest_timestamp']} ~ {final_db_stats['newest_timestamp']}")
                            
                            return total_stats
                        
                        # ç©ºé¡µé¢ä¹Ÿç®—æˆåŠŸï¼Œé¿å…æ— é™é‡è¯•
                        page_success = True
                        break
                    else:
                        consecutive_empty_pages = 0  # é‡ç½®è¿ç»­ç©ºé¡µé¢è®¡æ•°
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ•°æ®ï¼ˆé¿å…é‡å¤çˆ¬å–å·²æœ‰æ•°æ®ï¼‰
                    new_topics_count = 0
                    for topic in topics:
                        topic_id = topic.get('topic_id')
                        self.db.cursor.execute('SELECT topic_id FROM topics WHERE topic_id = ?', (topic_id,))
                        if not self.db.cursor.fetchone():
                            new_topics_count += 1
                    
                    # å­˜å‚¨æ•°æ®
                    page_stats = self.store_batch_data(data)
                    print(f"   ğŸ’¾ é¡µé¢å­˜å‚¨: æ–°å¢{page_stats['new_topics']}, æ›´æ–°{page_stats['updated_topics']}")
                    
                    # ç´¯è®¡ç»Ÿè®¡
                    total_stats['new_topics'] += page_stats['new_topics']
                    total_stats['updated_topics'] += page_stats['updated_topics']
                    total_stats['errors'] += page_stats['errors']
                    total_stats['pages'] += 1
                    
                    # æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
                    print(f"   ğŸ“Š è·å–åˆ° {len(topics)} ä¸ªè¯é¢˜ï¼Œå…¶ä¸­ {new_topics_count} ä¸ªä¸ºæ–°è¯é¢˜")
                    print(f"   ğŸ“ˆ ç´¯è®¡: æ–°å¢{total_stats['new_topics']}, æ›´æ–°{total_stats['updated_topics']}, é¡µæ•°{total_stats['pages']}")
                    
                    # è°ƒè¯•ï¼šæ˜¾ç¤ºæ—¶é—´æˆ³ä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆï¼‰
                    if topics:
                        first_time = topics[0].get('create_time', 'N/A')
                        last_time = topics[-1].get('create_time', 'N/A')
                        print(f"   â° æ—¶é—´èŒƒå›´: {first_time} ~ {last_time}")
                    
                    # å‡†å¤‡ä¸‹ä¸€é¡µçš„æ—¶é—´æˆ³
                    if topics:
                        original_time = topics[-1].get('create_time')
                        try:
                            from datetime import datetime, timedelta
                            dt = datetime.fromisoformat(original_time.replace('+0800', '+08:00'))
                            dt = dt - timedelta(milliseconds=self.timestamp_offset_ms)
                            end_time = dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + '+0800'
                        except Exception as e:
                            end_time = original_time
                            print(f"   âš ï¸ æ—¶é—´æˆ³è°ƒæ•´å¤±è´¥: {e}")
                    
                    # æ£€æŸ¥æ˜¯å¦è¿”å›æ•°æ®é‡å°äºé¢„æœŸï¼ˆå¯èƒ½æ¥è¿‘åº•éƒ¨ï¼‰
                    if len(topics) < per_page:
                        print(f"   âš ï¸ è¿”å›æ•°æ®é‡({len(topics)})å°äºé¢„æœŸ({per_page})ï¼Œå¯èƒ½æ¥è¿‘å†å²åº•éƒ¨")
                    
                    # å¦‚æœæ²¡æœ‰æ–°è¯é¢˜ä¸”æ•°æ®é‡ä¸è¶³ï¼Œå¯èƒ½å·²è¾¾å†å²åº•éƒ¨
                    if new_topics_count == 0 and len(topics) < per_page:
                        print(f"   ğŸ“­ æ— æ–°è¯é¢˜ä¸”æ•°æ®é‡ä¸è¶³ï¼Œå¯èƒ½å·²è¾¾å†å²åº•éƒ¨")
                        return total_stats
                    
                    # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    page_success = True
                    break
                else:
                    # å¤±è´¥ï¼Œå¢åŠ é‡è¯•è®¡æ•°å’Œé”™è¯¯è®¡æ•°
                    retry_count += 1
                    total_stats['errors'] += 1
                    print(f"   âŒ é¡µé¢ {current_page} è·å–å¤±è´¥ (é‡è¯•{retry_count}/{max_retries_per_page})")
                    
                    # è°ƒæ•´æ—¶é—´æˆ³ç”¨äºé‡è¯•
                    if end_time:
                        try:
                            from datetime import datetime, timedelta
                            dt = datetime.fromisoformat(end_time.replace('+0800', '+08:00'))
                            dt = dt - timedelta(milliseconds=self.timestamp_offset_ms)
                            end_time = dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + '+0800'
                        except Exception as e:
                            print(f"   âš ï¸ æ—¶é—´æˆ³è°ƒæ•´å¤±è´¥: {e}")
            
            # å¦‚æœé‡è¯•æ¬¡æ•°ç”¨å®Œä»ç„¶å¤±è´¥
            if not page_success:
                print(f"   ğŸš« é¡µé¢ {current_page} è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                # å¤§å¹…åº¦è·³è¿‡é—®é¢˜åŒºåŸŸ
                if end_time:
                    try:
                        from datetime import datetime, timedelta
                        dt = datetime.fromisoformat(end_time.replace('+0800', '+08:00'))
                        dt = dt - timedelta(hours=1)
                        end_time = dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + '+0800'
                        print(f"   â° å¤§å¹…åº¦è·³è¿‡æ—¶é—´æ®µ: {end_time} (å‡å»1å°æ—¶)")
                    except Exception as e:
                        print(f"   âš ï¸ å¤§å¹…åº¦æ—¶é—´æˆ³è°ƒæ•´å¤±è´¥: {e}")
                completed_pages += 1  # è·³è¿‡è¿™ä¸€é¡µ
            else:
                # é¡µé¢æˆåŠŸå¤„ç†åè¿›è¡Œé•¿ä¼‘çœ æ£€æŸ¥ï¼ˆåŸºäºé¡µé¢æ•°è€Œéè¯·æ±‚æ•°ï¼‰
                self.check_page_long_delay()
            
            # æ¯50é¡µæ˜¾ç¤ºä¸€æ¬¡æ€»ä½“è¿›åº¦
            if current_page % 50 == 0:
                print(f"\nğŸ¯ è¿›åº¦æŠ¥å‘Š (ç¬¬{current_page}é¡µ):")
                print(f"   ğŸ“Š ç´¯è®¡æ–°å¢: {total_stats['new_topics']}")
                print(f"   ğŸ“Š ç´¯è®¡æ›´æ–°: {total_stats['updated_topics']}")
                print(f"   ğŸ“Š æˆåŠŸé¡µæ•°: {total_stats['pages']}")
                print(f"   ğŸ“Š é”™è¯¯æ¬¡æ•°: {total_stats['errors']}")
                
                # æ˜¾ç¤ºå½“å‰æ•°æ®åº“çŠ¶æ€
                current_db_stats = self.db.get_timestamp_range_info()
                if current_db_stats['has_data']:
                    print(f"   ğŸ“Š æ•°æ®åº“çŠ¶æ€: {current_db_stats['total_topics']}ä¸ªè¯é¢˜")
                    print(f"   ğŸ“Š æ—¶é—´èŒƒå›´: {current_db_stats['oldest_timestamp']} ~ {current_db_stats['newest_timestamp']}")
        
        # è¿™é‡Œç†è®ºä¸Šä¸ä¼šåˆ°è¾¾ï¼Œå› ä¸ºåœ¨å¾ªç¯å†…ä¼šreturn
        return total_stats
    
    def crawl_incremental(self, pages: int = 10, per_page: int = 20) -> Dict[str, int]:
        """å¢é‡çˆ¬å–ï¼šåŸºäºæ•°æ®åº“æœ€è€æ—¶é—´æˆ³ç»§ç»­å‘å†å²çˆ¬å–"""
        print(f"\nğŸ“ˆ å¢é‡çˆ¬å–æ¨¡å¼: {pages}é¡µ x {per_page}æ¡/é¡µ")
        
        # è·å–æ•°æ®åº“æ—¶é—´æˆ³èŒƒå›´ä¿¡æ¯
        timestamp_info = self.db.get_timestamp_range_info()
        
        if not timestamp_info['has_data']:
            print("âŒ æ•°æ®åº“ä¸­æ²¡æœ‰è¯é¢˜æ•°æ®ï¼Œè¯·å…ˆè¿›è¡Œå†å²çˆ¬å–")
            return {'new_topics': 0, 'updated_topics': 0, 'errors': 1}
        
        oldest_timestamp = timestamp_info['oldest_timestamp']
        total_existing = timestamp_info['total_topics']
        
        print(f"ğŸ“Š æ•°æ®åº“çŠ¶æ€:")
        print(f"   ç°æœ‰è¯é¢˜æ•°: {total_existing}")
        print(f"   æœ€è€æ—¶é—´æˆ³: {oldest_timestamp}")
        print(f"   æœ€æ–°æ—¶é—´æˆ³: {timestamp_info['newest_timestamp']}")
        print(f"ğŸ¯ å°†ä»æœ€è€æ—¶é—´æˆ³å¼€å§‹ç»§ç»­å‘å†å²çˆ¬å–...")
        
        # å‡†å¤‡å¢é‡çˆ¬å–çš„èµ·å§‹æ—¶é—´æˆ³ï¼ˆåœ¨æœ€è€æ—¶é—´æˆ³åŸºç¡€ä¸Šå‡å»åç§»é‡ï¼‰
        try:
            from datetime import datetime, timedelta
            dt = datetime.fromisoformat(oldest_timestamp.replace('+0800', '+08:00'))
            dt = dt - timedelta(milliseconds=self.timestamp_offset_ms)
            start_end_time = dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + '+0800'
            print(f"ğŸš€ å¢é‡çˆ¬å–èµ·å§‹æ—¶é—´æˆ³: {start_end_time}")
        except Exception as e:
            print(f"âš ï¸ æ—¶é—´æˆ³å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸæ—¶é—´æˆ³: {e}")
            start_end_time = oldest_timestamp
        
        # æ‰§è¡Œå¢é‡çˆ¬å–
        total_stats = {'new_topics': 0, 'updated_topics': 0, 'errors': 0, 'pages': 0}
        end_time = start_end_time
        completed_pages = 0
        max_retries_per_page = 10
        
        while completed_pages < pages:
            current_page = completed_pages + 1
            print(f"\nğŸ“„ å¢é‡é¡µé¢ {current_page}/{pages}")
            retry_count = 0
            
            # é‡è¯•å½“å‰é¡µç›´åˆ°æˆåŠŸæˆ–è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
            while retry_count < max_retries_per_page:
                if retry_count > 0:
                    print(f"   ğŸ”„ ç¬¬{retry_count}æ¬¡é‡è¯•")
                
                # è·å–æ•°æ® - æ€»æ˜¯ä½¿ç”¨ end_time å‚æ•°
                data = self.fetch_topics_safe(scope="all", count=per_page, 
                                            end_time=end_time, is_historical=True)
                
                if data:
                    # æˆåŠŸè·å–æ•°æ®
                    topics = data.get('resp_data', {}).get('topics', [])
                    if not topics:
                        print(f"   ğŸ“­ æ— æ›´å¤šå†å²æ•°æ®ï¼Œå¢é‡çˆ¬å–å®Œæˆ")
                        return total_stats
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ•°æ®ï¼ˆé¿å…é‡å¤çˆ¬å–å·²æœ‰æ•°æ®ï¼‰
                    new_topics_count = 0
                    for topic in topics:
                        topic_id = topic.get('topic_id')
                        self.db.cursor.execute('SELECT topic_id FROM topics WHERE topic_id = ?', (topic_id,))
                        if not self.db.cursor.fetchone():
                            new_topics_count += 1
                    
                    print(f"   ğŸ“Š è·å–åˆ° {len(topics)} ä¸ªè¯é¢˜ï¼Œå…¶ä¸­ {new_topics_count} ä¸ªä¸ºæ–°è¯é¢˜")
                    
                    # å¦‚æœæ²¡æœ‰æ–°è¯é¢˜ä¸”å½“å‰é¡µè¯é¢˜æ•°å°‘äºé¢„æœŸï¼Œå¯èƒ½å·²åˆ°è¾¾å†å²åº•éƒ¨
                    if new_topics_count == 0 and len(topics) < per_page:
                        print(f"   ğŸ“­ æ— æ–°è¯é¢˜ä¸”æ•°æ®é‡ä¸è¶³ï¼Œå¯èƒ½å·²è¾¾å†å²åº•éƒ¨")
                        return total_stats
                    
                    # å­˜å‚¨æ•°æ®
                    page_stats = self.store_batch_data(data)
                    print(f"   ğŸ’¾ é¡µé¢å­˜å‚¨: æ–°å¢{page_stats['new_topics']}, æ›´æ–°{page_stats['updated_topics']}")
                    
                    # ç´¯è®¡ç»Ÿè®¡
                    total_stats['new_topics'] += page_stats['new_topics']
                    total_stats['updated_topics'] += page_stats['updated_topics']
                    total_stats['errors'] += page_stats['errors']
                    total_stats['pages'] += 1
                    completed_pages += 1
                    
                    # è°ƒè¯•ï¼šæ˜¾ç¤ºè¯é¢˜æ—¶é—´æˆ³ä¿¡æ¯
                    if self.debug_mode:
                        print(f"   ğŸ” è°ƒè¯•ä¿¡æ¯:")
                        print(f"   ğŸ“Š æœ¬é¡µè·å–åˆ° {len(topics)} ä¸ªè¯é¢˜")
                        for i, topic in enumerate(topics):
                            topic_time = topic.get('create_time', 'N/A')
                            topic_title = topic.get('title', 'æ— æ ‡é¢˜')[:30]
                            print(f"   {i+1:2d}. {topic_time} - {topic_title}")
                    
                    # å‡†å¤‡ä¸‹ä¸€é¡µçš„æ—¶é—´æˆ³
                    if topics:
                        original_time = topics[-1].get('create_time')
                        try:
                            dt = datetime.fromisoformat(original_time.replace('+0800', '+08:00'))
                            dt = dt - timedelta(milliseconds=self.timestamp_offset_ms)
                            end_time = dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + '+0800'
                            print(f"   â­ï¸ ä¸‹ä¸€é¡µæ—¶é—´æˆ³: {end_time}")
                        except Exception as e:
                            end_time = original_time
                            print(f"   âš ï¸ æ—¶é—´æˆ³è°ƒæ•´å¤±è´¥: {e}")
                    
                    # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    self.check_page_long_delay()  # é¡µé¢æˆåŠŸå¤„ç†åè¿›è¡Œé•¿ä¼‘çœ æ£€æŸ¥
                    break
                else:
                    # å¤±è´¥ï¼Œå¢åŠ é‡è¯•è®¡æ•°å’Œé”™è¯¯è®¡æ•°
                    retry_count += 1
                    total_stats['errors'] += 1
                    print(f"   âŒ é¡µé¢ {current_page} è·å–å¤±è´¥ (é‡è¯•{retry_count}/{max_retries_per_page})")
                    
                    # è°ƒæ•´æ—¶é—´æˆ³ç”¨äºé‡è¯•
                    if end_time:
                        try:
                            dt = datetime.fromisoformat(end_time.replace('+0800', '+08:00'))
                            dt = dt - timedelta(milliseconds=self.timestamp_offset_ms)
                            end_time = dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + '+0800'
                            print(f"   ğŸ”„ è°ƒæ•´æ—¶é—´æˆ³: {end_time}")
                        except Exception as e:
                            print(f"   âš ï¸ æ—¶é—´æˆ³è°ƒæ•´å¤±è´¥: {e}")
            
            # å¦‚æœé‡è¯•æ¬¡æ•°ç”¨å®Œä»ç„¶å¤±è´¥
            if retry_count >= max_retries_per_page:
                print(f"   ğŸš« é¡µé¢ {current_page} è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè·³è¿‡æ­¤é¡µ")
                # å¤§å¹…åº¦è·³è¿‡é—®é¢˜åŒºåŸŸ
                if end_time:
                    try:
                        dt = datetime.fromisoformat(end_time.replace('+0800', '+08:00'))
                        dt = dt - timedelta(hours=1)
                        end_time = dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + '+0800'
                        print(f"   â° å¤§å¹…åº¦è·³è¿‡æ—¶é—´æ®µ: {end_time} (å‡å»1å°æ—¶)")
                    except Exception as e:
                        print(f"   âš ï¸ å¤§å¹…åº¦æ—¶é—´æˆ³è°ƒæ•´å¤±è´¥: {e}")
                completed_pages += 1  # è·³è¿‡è¿™ä¸€é¡µ
        
        print(f"\nğŸ å¢é‡çˆ¬å–å®Œæˆ:")
        print(f"   ğŸ“„ æˆåŠŸé¡µæ•°: {total_stats['pages']}")
        print(f"   âœ… æ–°å¢è¯é¢˜: {total_stats['new_topics']}")
        print(f"   ğŸ”„ æ›´æ–°è¯é¢˜: {total_stats['updated_topics']}")
        if total_stats['errors'] > 0:
            print(f"   âŒ æ€»é”™è¯¯æ•°: {total_stats['errors']}")
        
        # æ˜¾ç¤ºæ›´æ–°åçš„æ•°æ®åº“çŠ¶æ€
        updated_info = self.db.get_timestamp_range_info()
        print(f"\nğŸ“Š æ›´æ–°åæ•°æ®åº“çŠ¶æ€:")
        print(f"   è¯é¢˜æ€»æ•°: {updated_info['total_topics']} (+{updated_info['total_topics'] - total_existing})")
        print(f"   æ—¶é—´èŒƒå›´: {updated_info['oldest_timestamp']} ~ {updated_info['newest_timestamp']}")
        
        return total_stats
    
    def crawl_latest_until_complete(self, per_page: int = 20) -> Dict[str, int]:
        """è·å–æœ€æ–°è®°å½•ï¼šæ™ºèƒ½å¢é‡æ›´æ–°ï¼Œçˆ¬å–åˆ°ä¸æ•°æ®åº“å®Œå…¨è¡”æ¥ä¸ºæ­¢"""
        print(f"\nğŸ”„ è·å–æœ€æ–°è®°å½•æ¨¡å¼ (æ¯é¡µ{per_page}æ¡)")
        print(f"ğŸ’¡ æ™ºèƒ½é€»è¾‘ï¼šæ£€æŸ¥æœ€æ–°è¯é¢˜ï¼Œå¦‚æœ‰æ–°å†…å®¹åˆ™å‘åçˆ¬å–ç›´åˆ°ä¸æ•°æ®åº“å®Œå…¨è¡”æ¥")
        
        # æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
        timestamp_info = self.db.get_timestamp_range_info()
        if not timestamp_info['has_data']:
            print("âŒ æ•°æ®åº“ä¸ºç©ºï¼Œè¯·å…ˆè¿›è¡Œå†å²æ•°æ®çˆ¬å–")
            return {'new_topics': 0, 'updated_topics': 0, 'errors': 0, 'pages': 0}
        
        print(f"ğŸ“Š æ•°æ®åº“çŠ¶æ€:")
        print(f"   ç°æœ‰è¯é¢˜æ•°: {timestamp_info['total_topics']}")
        print(f"   æœ€æ–°æ—¶é—´æˆ³: {timestamp_info['newest_timestamp']}")
        
        total_stats = {'new_topics': 0, 'updated_topics': 0, 'errors': 0, 'pages': 0}
        end_time = None  # ä»æœ€æ–°å¼€å§‹
        current_page = 0
        max_retries_per_page = 10
        
        while True:
            current_page += 1
            print(f"\nğŸ“„ æ£€æŸ¥é¡µé¢ {current_page}")
            retry_count = 0
            page_success = False
            
            # é‡è¯•å½“å‰é¡µç›´åˆ°æˆåŠŸæˆ–è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
            while retry_count < max_retries_per_page:
                if retry_count > 0:
                    print(f"   ğŸ”„ ç¬¬{retry_count}æ¬¡é‡è¯•")
                
                # è·å–æ•°æ®
                if current_page == 1:
                    # ç¬¬ä¸€é¡µï¼šè·å–æœ€æ–°è¯é¢˜
                    data = self.fetch_topics_safe(scope="all", count=per_page, is_historical=False)
                else:
                    # åç»­é¡µé¢ï¼šä½¿ç”¨ end_time å‘å†å²çˆ¬å–
                    data = self.fetch_topics_safe(scope="all", count=per_page, 
                                                end_time=end_time, is_historical=True)
                
                if data:
                    # æˆåŠŸè·å–æ•°æ®
                    topics = data.get('resp_data', {}).get('topics', [])
                    
                    if not topics:
                        print(f"   ğŸ“­ æ— æ›´å¤šæ•°æ®ï¼Œè·å–å®Œæˆ")
                        break
                    
                    # æ£€æŸ¥è¿™ä¸€é¡µçš„è¯é¢˜æ˜¯å¦åœ¨æ•°æ®åº“ä¸­å…¨éƒ¨å­˜åœ¨
                    existing_count = 0
                    new_topics_list = []
                    
                    for topic in topics:
                        topic_id = topic.get('topic_id')
                        self.db.cursor.execute('SELECT topic_id FROM topics WHERE topic_id = ?', (topic_id,))
                        if self.db.cursor.fetchone():
                            existing_count += 1
                        else:
                            new_topics_list.append(topic)
                    
                    print(f"   ğŸ“Š é¡µé¢åˆ†æ: {len(topics)}ä¸ªè¯é¢˜ï¼Œ{existing_count}ä¸ªå·²å­˜åœ¨ï¼Œ{len(new_topics_list)}ä¸ªæ–°è¯é¢˜")
                    
                    # åˆ¤æ–­æ˜¯å¦éœ€è¦åœæ­¢
                    if existing_count == len(topics):
                        # æ•´é¡µè¯é¢˜å…¨éƒ¨å­˜åœ¨äºæ•°æ®åº“ä¸­
                        print(f"   âœ… æ•´é¡µè¯é¢˜å…¨éƒ¨å­˜åœ¨äºæ•°æ®åº“ï¼Œå¢é‡æ›´æ–°å®Œæˆ")
                        print(f"\nğŸ‰ è·å–æœ€æ–°è®°å½•å®Œæˆæ€»ç»“:")
                        print(f"   ğŸ“„ æ£€æŸ¥é¡µæ•°: {total_stats['pages']}")
                        print(f"   âœ… æ–°å¢è¯é¢˜: {total_stats['new_topics']}")
                        print(f"   ğŸ”„ æ›´æ–°è¯é¢˜: {total_stats['updated_topics']}")
                        if total_stats['errors'] > 0:
                            print(f"   âŒ æ€»é”™è¯¯æ•°: {total_stats['errors']}")
                        
                        # æ˜¾ç¤ºæ›´æ–°åçš„æ•°æ®åº“çŠ¶æ€
                        final_db_stats = self.db.get_timestamp_range_info()
                        if final_db_stats['has_data']:
                            print(f"\nğŸ“Š æ•°æ®åº“æœ€ç»ˆçŠ¶æ€:")
                            print(f"   è¯é¢˜æ€»æ•°: {final_db_stats['total_topics']} (+{final_db_stats['total_topics'] - timestamp_info['total_topics']})")
                            print(f"   æ—¶é—´èŒƒå›´: {final_db_stats['oldest_timestamp']} ~ {final_db_stats['newest_timestamp']}")
                        
                        return total_stats
                    
                    elif existing_count == 0:
                        # æ•´é¡µè¯é¢˜éƒ½æ˜¯æ–°çš„ï¼Œå…¨éƒ¨å­˜å‚¨
                        page_stats = self.store_batch_data(data)
                        print(f"   ğŸ’¾ æ•´é¡µå­˜å‚¨: æ–°å¢{page_stats['new_topics']}, æ›´æ–°{page_stats['updated_topics']}")
                    
                    else:
                        # éƒ¨åˆ†è¯é¢˜æ˜¯æ–°çš„ï¼Œåªå­˜å‚¨æ–°è¯é¢˜
                        print(f"   ğŸ’¾ éƒ¨åˆ†å­˜å‚¨: åªå¤„ç†{len(new_topics_list)}ä¸ªæ–°è¯é¢˜")
                        new_topics_count = 0
                        updated_topics_count = 0
                        
                        for new_topic in new_topics_list:
                            try:
                                topic_id = new_topic.get('topic_id')
                                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆåŒé‡æ£€æŸ¥ï¼‰
                                self.db.cursor.execute('SELECT topic_id FROM topics WHERE topic_id = ?', (topic_id,))
                                exists = self.db.cursor.fetchone()
                                
                                # å¯¼å…¥æ•°æ®
                                self.db.import_topic_data(new_topic)
                                
                                if exists:
                                    updated_topics_count += 1
                                else:
                                    new_topics_count += 1
                                    
                            except Exception as e:
                                print(f"   âš ï¸ è¯é¢˜å¯¼å…¥å¤±è´¥: {e}")
                        
                        # æäº¤äº‹åŠ¡
                        self.db.conn.commit()
                        print(f"   ğŸ’¾ æ–°è¯é¢˜å­˜å‚¨: æ–°å¢{new_topics_count}, æ›´æ–°{updated_topics_count}")
                        
                        # æ›´æ–°ç»Ÿè®¡
                        total_stats['new_topics'] += new_topics_count
                        total_stats['updated_topics'] += updated_topics_count
                    
                    # ç´¯è®¡ç»Ÿè®¡ï¼ˆå¦‚æœæ˜¯æ•´é¡µå­˜å‚¨ï¼‰
                    if existing_count == 0:
                        total_stats['new_topics'] += page_stats['new_topics']
                        total_stats['updated_topics'] += page_stats['updated_topics']
                        total_stats['errors'] += page_stats['errors']
                    
                    total_stats['pages'] += 1
                    
                    # æ˜¾ç¤ºå½“å‰è¿›åº¦
                    print(f"   ğŸ“ˆ ç´¯è®¡: æ–°å¢{total_stats['new_topics']}, æ›´æ–°{total_stats['updated_topics']}, é¡µæ•°{total_stats['pages']}")
                    
                    # æ˜¾ç¤ºæ—¶é—´æˆ³ä¿¡æ¯
                    if topics:
                        first_time = topics[0].get('create_time', 'N/A')
                        last_time = topics[-1].get('create_time', 'N/A')
                        print(f"   â° æ—¶é—´èŒƒå›´: {first_time} ~ {last_time}")
                    
                    # å‡†å¤‡ä¸‹ä¸€é¡µçš„æ—¶é—´æˆ³
                    if topics:
                        original_time = topics[-1].get('create_time')
                        try:
                            from datetime import datetime, timedelta
                            dt = datetime.fromisoformat(original_time.replace('+0800', '+08:00'))
                            dt = dt - timedelta(milliseconds=self.timestamp_offset_ms)
                            end_time = dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + '+0800'
                        except Exception as e:
                            end_time = original_time
                            print(f"   âš ï¸ æ—¶é—´æˆ³è°ƒæ•´å¤±è´¥: {e}")
                    
                    # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    page_success = True
                    break
                else:
                    # å¤±è´¥ï¼Œå¢åŠ é‡è¯•è®¡æ•°å’Œé”™è¯¯è®¡æ•°
                    retry_count += 1
                    total_stats['errors'] += 1
                    print(f"   âŒ é¡µé¢ {current_page} è·å–å¤±è´¥ (é‡è¯•{retry_count}/{max_retries_per_page})")
                    
                    # è°ƒæ•´æ—¶é—´æˆ³ç”¨äºé‡è¯•
                    if end_time:
                        try:
                            from datetime import datetime, timedelta
                            dt = datetime.fromisoformat(end_time.replace('+0800', '+08:00'))
                            dt = dt - timedelta(milliseconds=self.timestamp_offset_ms)
                            end_time = dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + '+0800'
                        except Exception as e:
                            print(f"   âš ï¸ æ—¶é—´æˆ³è°ƒæ•´å¤±è´¥: {e}")
            
            # å¦‚æœé‡è¯•æ¬¡æ•°ç”¨å®Œä»ç„¶å¤±è´¥
            if not page_success:
                print(f"   ğŸš« é¡µé¢ {current_page} è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œåœæ­¢è·å–")
                break
            else:
                # é¡µé¢æˆåŠŸå¤„ç†åè¿›è¡Œé•¿ä¼‘çœ æ£€æŸ¥ï¼ˆåŸºäºé¡µé¢æ•°è€Œéè¯·æ±‚æ•°ï¼‰
                self.check_page_long_delay()
        
        return total_stats
    
    def show_menu(self):
        """æ˜¾ç¤ºäº¤äº’èœå•"""
        print(f"\n{'='*60}")
        print("ğŸ•·ï¸ çŸ¥è¯†æ˜Ÿçƒäº¤äº’å¼æ•°æ®é‡‡é›†å™¨")
        print("="*60)
        print("ğŸ“ è¯é¢˜é‡‡é›†åŠŸèƒ½:")
        print("1. è·å–æ‰€æœ‰å†å²æ•°æ® (æ— é™çˆ¬å–) - é€‚åˆï¼šå…¨é‡å½’æ¡£ï¼Œä»æœ€è€æ•°æ®æ— é™æŒ–æ˜")
        print("2. å¢é‡çˆ¬å–å†å² (åŸºäºæ•°æ®åº“æœ€è€æ—¶é—´æˆ³) - é€‚åˆï¼šç²¾ç¡®è¡¥å……å†å²ï¼Œæœ‰ç›®æ ‡çš„å›å¡«")
        print("3. è·å–æœ€æ–°è®°å½• (æ™ºèƒ½å¢é‡æ›´æ–°) - é€‚åˆï¼šæ—¥å¸¸ç»´æŠ¤ï¼Œè‡ªåŠ¨æ£€æµ‹å¹¶åªçˆ¬æ–°å†…å®¹")
        print("")
        print("ğŸ“¥ æ–‡ä»¶ä¸‹è½½åŠŸèƒ½:")
        print("4. å¢é‡æ”¶é›†æ–‡ä»¶åˆ—è¡¨ - é€‚åˆï¼šä»æ•°æ®åº“æœ€è€æ—¶é—´æˆ³ç»§ç»­æ”¶é›†æ›´æ—©æ–‡ä»¶")
        print("5. æŸ¥çœ‹æ–‡ä»¶æ•°æ®åº“ç»Ÿè®¡ - é€‚åˆï¼šæŸ¥çœ‹æ”¶é›†çš„æ–‡ä»¶ä¿¡æ¯å’Œä¸‹è½½çŠ¶æ€")
        print("6. æŒ‰ä¸‹è½½æ¬¡æ•°ä¸‹è½½æ–‡ä»¶ - é€‚åˆï¼šè‡ªåŠ¨æ”¶é›†çƒ­é—¨æ–‡ä»¶å¹¶æŒ‰ä¸‹è½½æ¬¡æ•°æ’åºä¸‹è½½")
        print("7. æŒ‰æ—¶é—´é¡ºåºä¸‹è½½æ–‡ä»¶ - é€‚åˆï¼šè‡ªåŠ¨æ”¶é›†æ–‡ä»¶åˆ—è¡¨å¹¶æŒ‰æ—¶é—´é¡ºåºä¸‹è½½")
        print("8. æ–‡ä»¶ä¸‹è½½è®¾ç½® - é€‚åˆï¼šè°ƒæ•´ä¸‹è½½é—´éš”å’Œä¼‘çœ å‚æ•°")
        print("")
        print("âš™ï¸ ç³»ç»ŸåŠŸèƒ½:")
        print("9. æŸ¥çœ‹è¯é¢˜æ•°æ®åº“ç»Ÿè®¡ - é€‚åˆï¼šç›‘æ§è¯é¢˜æ•°æ®çŠ¶æ€ï¼Œäº†è§£å½“å‰æ•°æ®èŒƒå›´")
        print("10. è°ƒæ•´åæ£€æµ‹è®¾ç½® - é€‚åˆï¼šä¼˜åŒ–çˆ¬å–é€Ÿåº¦ï¼Œåº”å¯¹ä¸åŒç½‘ç»œç¯å¢ƒ")
        print(f"11. æ—¶é—´æˆ³è®¾ç½® (å½“å‰: å‡å»{self.timestamp_offset_ms}æ¯«ç§’) - é€‚åˆï¼šè§£å†³æ—¶é—´ç‚¹å†²çªï¼Œç²¾ç¡®æ§åˆ¶åˆ†é¡µ")
        print(f"12. è°ƒè¯•æ¨¡å¼ (å½“å‰: {'å¼€å¯' if self.debug_mode else 'å…³é—­'}) - é€‚åˆï¼šæ’æŸ¥é—®é¢˜ï¼ŒæŸ¥çœ‹è¯¦ç»†è¯·æ±‚ä¿¡æ¯")
        print("13. é€€å‡ºç¨‹åº")
        print("="*60)
    
    def adjust_stealth_settings(self):
        """è°ƒæ•´åæ£€æµ‹è®¾ç½®"""
        print(f"\nğŸ”§ å½“å‰åæ£€æµ‹è®¾ç½®:")
        print(f"   æœ€å°å»¶è¿Ÿ: {self.min_delay}ç§’")
        print(f"   æœ€å¤§å»¶è¿Ÿ: {self.max_delay}ç§’")
        print(f"   é•¿å»¶è¿Ÿé—´éš”: æ¯{self.long_delay_interval}ä¸ªé¡µé¢")
        print(f"   é•¿ä¼‘çœ æ—¶é—´: 3-5åˆ†é’Ÿ (180-300ç§’)")
        print(f"ğŸ’¡ è¯´æ˜: é•¿ä¼‘çœ åŸºäºæˆåŠŸå¤„ç†çš„é¡µé¢æ•°ï¼Œè€Œéè¯·æ±‚æ•°ï¼Œæ›´åŠ åˆç†ç¨³å®š")
        
        try:
            new_min = float(input(f"æ–°çš„æœ€å°å»¶è¿Ÿ (å½“å‰{self.min_delay}): ") or self.min_delay)
            new_max = float(input(f"æ–°çš„æœ€å¤§å»¶è¿Ÿ (å½“å‰{self.max_delay}): ") or self.max_delay)
            new_interval = int(input(f"é•¿å»¶è¿Ÿé—´éš” (å½“å‰æ¯{self.long_delay_interval}é¡µ): ") or self.long_delay_interval)
            
            self.min_delay = max(new_min, 1.0)  # æœ€å°1ç§’
            self.max_delay = max(new_max, self.min_delay + 1.0)
            self.long_delay_interval = max(new_interval, 5)
            
            print(f"âœ… è®¾ç½®å·²æ›´æ–°")
            print(f"ğŸ’¡ é•¿ä¼‘çœ æ—¶é—´å›ºå®šä¸º3-5åˆ†é’Ÿï¼Œæœ‰åŠ©äºæ›´å¥½åœ°æ¨¡æ‹Ÿäººç±»è¡Œä¸º")
            print(f"ğŸ¯ é•¿ä¼‘çœ è§¦å‘ï¼šæ¯æˆåŠŸå¤„ç†{self.long_delay_interval}ä¸ªé¡µé¢è¿›è¡Œä¸€æ¬¡é•¿ä¼‘çœ ")
            
        except ValueError:
            print("âŒ è¾“å…¥æ— æ•ˆï¼Œä¿æŒåŸè®¾ç½®")
    
    def adjust_timestamp_settings(self):
        """è°ƒæ•´æ—¶é—´æˆ³è®¾ç½®"""
        print(f"\nâ° å½“å‰æ—¶é—´æˆ³è®¾ç½®:")
        print(f"   å‡å»æ¯«ç§’æ•°: {self.timestamp_offset_ms}æ¯«ç§’")
        print(f"\nğŸ’¡ è¯´æ˜:")
        print(f"   - å‡å»1æ¯«ç§’: æ ‡å‡†è®¾ç½®ï¼Œä¸å®˜ç½‘ä¸€è‡´")
        print(f"   - å‡å»2-3æ¯«ç§’: å¯èƒ½é¿å¼€æŸäº›é—®é¢˜æ—¶é—´ç‚¹")
        print(f"   - å‡å»5-10æ¯«ç§’: æ›´å¤§çš„å®¹é”™èŒƒå›´")
        
        try:
            new_offset = int(input(f"æ–°çš„æ¯«ç§’åç§»é‡ (å½“å‰{self.timestamp_offset_ms}): ") or self.timestamp_offset_ms)
            
            if new_offset < 0:
                print("âŒ æ¯«ç§’åç§»é‡ä¸èƒ½ä¸ºè´Ÿæ•°")
                return
            
            self.timestamp_offset_ms = new_offset
            print(f"âœ… æ—¶é—´æˆ³è®¾ç½®å·²æ›´æ–°: å‡å»{self.timestamp_offset_ms}æ¯«ç§’")
            
        except ValueError:
            print("âŒ è¾“å…¥æ— æ•ˆï¼Œä¿æŒåŸè®¾ç½®")
    
    def run_interactive(self):
        """è¿è¡Œäº¤äº’å¼ç•Œé¢"""
        try:
            while True:
                self.show_menu()
                choice = input("\nè¯·é€‰æ‹© (1-13): ").strip()
                
                if choice == "1":
                    per_page = int(input("æ¯é¡µæ•°é‡ (é»˜è®¤20): ") or "20")
                    self.crawl_all_historical(per_page)
                    
                elif choice == "2":
                    pages = int(input("çˆ¬å–é¡µæ•° (é»˜è®¤10): ") or "10")
                    per_page = int(input("æ¯é¡µæ•°é‡ (é»˜è®¤20): ") or "20")
                    self.crawl_incremental(pages, per_page)
                    
                elif choice == "3":
                    per_page = int(input("æ¯é¡µæ•°é‡ (é»˜è®¤20): ") or "20")
                    self.crawl_latest_until_complete(per_page)
                    
                elif choice == "4":
                    # å¢é‡æ”¶é›†æ–‡ä»¶åˆ—è¡¨
                    downloader = self.get_file_downloader()
                    downloader.collect_incremental_files()
                    
                elif choice == "5":
                    # æŸ¥çœ‹æ–‡ä»¶æ•°æ®åº“ç»Ÿè®¡
                    downloader = self.get_file_downloader()
                    downloader.show_database_stats()
                    
                elif choice == "6":
                    # æŒ‰ä¸‹è½½æ¬¡æ•°ä¸‹è½½æ–‡ä»¶ (é›†æˆæ”¶é›†å’Œä¸‹è½½)
                    downloader = self.get_file_downloader()
                    
                    # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å·²æœ‰æ–‡ä»¶æ•°æ®
                    stats = downloader.file_db.get_database_stats()
                    existing_files = stats.get('files', 0)
                    
                    if existing_files > 0:
                        print(f"ğŸ“Š æ•°æ®åº“ä¸­å·²æœ‰ {existing_files} ä¸ªæ–‡ä»¶è®°å½•")
                        collect_confirm = input("æ˜¯å¦é‡æ–°æ”¶é›†æ–‡ä»¶åˆ—è¡¨? (y/n, é»˜è®¤nç›´æ¥ä¸‹è½½): ").strip().lower()
                        if collect_confirm != 'y':
                            print("âš¡ ç›´æ¥ä½¿ç”¨ç°æœ‰æ•°æ®è¿›è¡Œä¸‹è½½...")
                        else:
                            print("ğŸ”„ æŒ‰ä¸‹è½½æ¬¡æ•°é‡æ–°æ”¶é›†æ–‡ä»¶åˆ—è¡¨...")
                            downloader.collect_all_files_to_database()
                    else:
                        print("ğŸ”„ æŒ‰ä¸‹è½½æ¬¡æ•°æ”¶é›†çƒ­é—¨æ–‡ä»¶åˆ—è¡¨...")
                        downloader.collect_all_files_to_database()
                    
                    # è‡ªåŠ¨å¼€å§‹ä¸‹è½½
                    print("\nğŸš€ è‡ªåŠ¨å¼€å§‹ä¸‹è½½æ–‡ä»¶...")
                    user_input = input("æœ€å¤§ä¸‹è½½æ–‡ä»¶æ•° (é»˜è®¤æ— é™ï¼Œè¾“å…¥æ•°å­—é™åˆ¶): ").strip()
                    if user_input and user_input.isdigit():
                        max_files = int(user_input)
                    else:
                        max_files = None
                    downloader.download_files_from_database(max_files=max_files, status_filter='pending')
                    
                elif choice == "7":
                    # æŒ‰æ—¶é—´é¡ºåºä¸‹è½½æ–‡ä»¶ (é›†æˆæ”¶é›†å’Œä¸‹è½½)
                    downloader = self.get_file_downloader()
                    
                    # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å·²æœ‰æ–‡ä»¶æ•°æ®
                    stats = downloader.file_db.get_database_stats()
                    existing_files = stats.get('files', 0)
                    
                    if existing_files > 0:
                        print(f"ğŸ“Š æ•°æ®åº“ä¸­å·²æœ‰ {existing_files} ä¸ªæ–‡ä»¶è®°å½•")
                        collect_confirm = input("æ˜¯å¦é‡æ–°æ”¶é›†æ–‡ä»¶åˆ—è¡¨? (y/n, é»˜è®¤nç›´æ¥ä¸‹è½½): ").strip().lower()
                        if collect_confirm != 'y':
                            print("âš¡ ç›´æ¥ä½¿ç”¨ç°æœ‰æ•°æ®è¿›è¡Œä¸‹è½½...")
                        else:
                            print("ğŸ”„ æŒ‰æ—¶é—´æ’åºé‡æ–°æ”¶é›†æ–‡ä»¶åˆ—è¡¨...")
                            downloader.collect_files_by_time()
                    else:
                        print("ğŸ”„ æŒ‰æ—¶é—´æ’åºæ”¶é›†æ–‡ä»¶åˆ—è¡¨...")
                        downloader.collect_files_by_time()
                    
                    # è‡ªåŠ¨å¼€å§‹ä¸‹è½½
                    print("\nğŸš€ è‡ªåŠ¨å¼€å§‹ä¸‹è½½æ–‡ä»¶...")
                    user_input = input("æœ€å¤§ä¸‹è½½æ–‡ä»¶æ•° (é»˜è®¤æ— é™ï¼Œè¾“å…¥æ•°å­—é™åˆ¶): ").strip()
                    if user_input and user_input.isdigit():
                        max_files = int(user_input)
                    else:
                        max_files = None
                    downloader.download_files_from_database(max_files=max_files, status_filter='pending')
                    
                elif choice == "8":
                    # æ–‡ä»¶ä¸‹è½½è®¾ç½®
                    downloader = self.get_file_downloader()
                    downloader.adjust_settings()
                    
                elif choice == "9":
                    # æŸ¥çœ‹è¯é¢˜æ•°æ®åº“ç»Ÿè®¡
                    self.show_database_status()
                    stats = self.db.get_database_stats()
                    print("\nğŸ“Š è¯¦ç»†ç»Ÿè®¡:")
                    for table, count in stats.items():
                        print(f"   {table}: {count}")
                    
                elif choice == "10":
                    self.adjust_stealth_settings()
                
                elif choice == "11":
                    self.adjust_timestamp_settings()
                    
                elif choice == "12":
                    self.debug_mode = not self.debug_mode
                    status = "å¼€å¯" if self.debug_mode else "å…³é—­"
                    print(f"ğŸ” è°ƒè¯•æ¨¡å¼å·²{status}")
                    if self.debug_mode:
                        print("âš ï¸ è°ƒè¯•æ¨¡å¼ä¼šè¾“å‡ºè¯¦ç»†çš„è¯·æ±‚ä¿¡æ¯ï¼ŒåŒ…æ‹¬å®Œæ•´çš„å¤±è´¥å“åº”")
                    
                elif choice == "13":
                    print("ğŸ‘‹ é€€å‡ºç¨‹åº")
                    break
                    
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©")
                
                input("\næŒ‰å›è½¦é”®ç»§ç»­...")
                
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"âŒ ç¨‹åºå¼‚å¸¸: {e}")
        finally:
            self.close()
    
    def close(self):
        """å…³é—­èµ„æº"""
        self.db.close()
        print("ğŸ”’ æ•°æ®åº“è¿æ¥å·²å…³é—­")


def load_config():
    """åŠ è½½TOMLé…ç½®æ–‡ä»¶"""
    if tomllib is None:
        return None
        
    config_file = "config.toml"
    if not os.path.exists(config_file):
        print("âš ï¸ æœªæ‰¾åˆ°config.tomlé…ç½®æ–‡ä»¶ï¼Œè¯·å…ˆåˆ›å»ºå¹¶é…ç½®")
        print("ğŸ’¡ å¯ä»¥å¤åˆ¶config.toml.exampleä¸ºconfig.tomlå¹¶ä¿®æ”¹")
        return None
    
    try:
        with open(config_file, 'rb') as f:
            config = tomllib.load(f)
        
        print("âœ… å·²ä»config.tomlåŠ è½½é…ç½®")
        return config
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å‡ºé”™: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½é…ç½®ä¿¡æ¯
    config = load_config()
    if not config:
        return
    
    # ä»TOMLé…ç½®ä¸­è·å–å€¼
    auth_config = config.get('auth', {})
    db_config = config.get('database', {})
    
    COOKIE = auth_config.get('cookie', 'your_cookie_here')
    GROUP_ID = auth_config.get('group_id', 'your_group_id_here')
    DB_PATH = db_config.get('path', 'zsxq_interactive.db')
    
    # æ£€æŸ¥é…ç½®æ˜¯å¦å·²ä¿®æ”¹
    if COOKIE == "your_cookie_here" or GROUP_ID == "your_group_id_here":
        print("âš ï¸ è¯·å…ˆåœ¨config.tomlä¸­é…ç½®æ‚¨çš„cookieå’Œgroup_id")
        return
    
    # åˆ›å»ºäº¤äº’å¼çˆ¬è™«
    crawler = ZSXQInteractiveCrawler(COOKIE, GROUP_ID, DB_PATH)
    
    # è¿è¡Œäº¤äº’ç•Œé¢
    crawler.run_interactive()


if __name__ == "__main__":
    main()