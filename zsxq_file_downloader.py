#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥è¯†æ˜Ÿçƒæ–‡ä»¶ä¸‹è½½å™¨
Author: AI Assistant
Date: 2024-12-19
Description: ä¸“é—¨ç”¨äºä¸‹è½½çŸ¥è¯†æ˜Ÿçƒæ–‡ä»¶çš„å·¥å…·
"""

import datetime
import json
import os
import random
import time
from typing import Dict, Optional, Any

import requests

from zsxq_file_database import ZSXQFileDatabase


class ZSXQFileDownloader:
    """çŸ¥è¯†æ˜Ÿçƒæ–‡ä»¶ä¸‹è½½å™¨"""
    
    def __init__(self, cookie: str, group_id: str, download_dir: str = "downloads", db_path: str = "zsxq_files_complete.db"):
        """
        åˆå§‹åŒ–æ–‡ä»¶ä¸‹è½½å™¨
        
        Args:
            cookie: ç™»å½•å‡­è¯
            group_id: æ˜ŸçƒID
            download_dir: ä¸‹è½½ç›®å½•
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        self.cookie = self.clean_cookie(cookie)
        self.group_id = group_id
        self.download_dir = download_dir
        self.db_path = db_path
        self.base_url = "https://api.zsxq.com"
        
        # åæ£€æµ‹è®¾ç½®
        self.min_delay = 2.0  # æœ€å°å»¶è¿Ÿï¼ˆç§’ï¼‰
        self.max_delay = 5.0  # æœ€å¤§å»¶è¿Ÿï¼ˆç§’ï¼‰
        self.download_interval_min = 60  # ä¸‹è½½é—´éš”æœ€å°å€¼ï¼ˆ1åˆ†é’Ÿï¼‰
        self.download_interval_max = 180  # ä¸‹è½½é—´éš”æœ€å¤§å€¼ï¼ˆ3åˆ†é’Ÿï¼‰
        self.long_delay_interval = 5  # æ¯Nä¸ªæ–‡ä»¶è¿›è¡Œé•¿ä¼‘çœ 
        self.long_delay_min = 180  # é•¿ä¼‘çœ æœ€å°å€¼ï¼ˆ3åˆ†é’Ÿï¼‰
        self.long_delay_max = 300  # é•¿ä¼‘çœ æœ€å¤§å€¼ï¼ˆ5åˆ†é’Ÿï¼‰
        
        # ç»Ÿè®¡
        self.request_count = 0
        self.download_count = 0
        self.debug_mode = False
        
        # åˆ›å»ºsession
        self.session = requests.Session()
        
        # ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
        os.makedirs(download_dir, exist_ok=True)
        print(f"ğŸ“ ä¸‹è½½ç›®å½•: {os.path.abspath(download_dir)}")
        
        # ä½¿ç”¨å®Œæ•´çš„æ–‡ä»¶æ•°æ®åº“
        self.file_db = ZSXQFileDatabase(db_path)
        print(f"ğŸ“Š å®Œæ•´æ–‡ä»¶æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {db_path}")
    
    def clean_cookie(self, cookie: str) -> str:
        """æ¸…ç†Cookieå­—ç¬¦ä¸²ï¼Œå»é™¤ä¸åˆæ³•å­—ç¬¦
        
        Args:
            cookie (str): åŸå§‹Cookieå­—ç¬¦ä¸²
        
        Returns:
            str: æ¸…ç†åçš„Cookieå­—ç¬¦ä¸²
        """
        try:
            # å¦‚æœæ˜¯bytesç±»å‹ï¼Œå…ˆè§£ç 
            if isinstance(cookie, bytes):
                cookie = cookie.decode('utf-8')
            
            # å»é™¤å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œç¬¦
            cookie = cookie.strip()
            
            # å¦‚æœæœ‰å¤šè¡Œï¼Œåªå–ç¬¬ä¸€è¡Œ
            if '\n' in cookie:
                cookie = cookie.split('\n')[0]
            
            # å»é™¤æœ«å°¾çš„åæ–œæ 
            cookie = cookie.rstrip('\\')
            
            # å»é™¤å¯èƒ½çš„å‰ç¼€bå’Œå¼•å·
            if cookie.startswith("b'") and cookie.endswith("'"):
                cookie = cookie[2:-1]
            elif cookie.startswith('b"') and cookie.endswith('"'):
                cookie = cookie[2:-1]
            elif cookie.startswith("'") and cookie.endswith("'"):
                cookie = cookie[1:-1]
            elif cookie.startswith('"') and cookie.endswith('"'):
                cookie = cookie[1:-1]
            
            # å¤„ç†è½¬ä¹‰å­—ç¬¦
            cookie = cookie.replace('\\n', '')
            cookie = cookie.replace('\\"', '"')
            cookie = cookie.replace("\\'", "'")
            
            # ç¡®ä¿åˆ†å·åæœ‰ç©ºæ ¼
            cookie = '; '.join(part.strip() for part in cookie.split(';'))
            
            return cookie
        except Exception as e:
            print(f"Cookieæ¸…ç†å¤±è´¥: {e}")
            return cookie  # è¿”å›åŸå§‹å€¼
    
    def get_stealth_headers(self) -> Dict[str, str]:
        """è·å–åæ£€æµ‹è¯·æ±‚å¤´ï¼ˆæ¯æ¬¡è°ƒç”¨éšæœºåŒ–ï¼‰"""
        # æ›´ä¸°å¯Œçš„User-Agentæ± 
        user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:132.0) Gecko/20100101 Firefox/132.0"
        ]
        
        # éšæœºé€‰æ‹©User-Agent
        selected_ua = random.choice(user_agents)
        
        # æ ¹æ®User-Agentç”Ÿæˆå¯¹åº”çš„Sec-Ch-Ua
        if "Chrome" in selected_ua:
            if "131.0.0.0" in selected_ua:
                sec_ch_ua = '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"'
            elif "130.0.0.0" in selected_ua:
                sec_ch_ua = '"Google Chrome";v="130", "Chromium";v="130", "Not?A_Brand";v="99"'
            elif "129.0.0.0" in selected_ua:
                sec_ch_ua = '"Google Chrome";v="129", "Not=A?Brand";v="8", "Chromium";v="129"'
            else:
                sec_ch_ua = '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"'
        else:
            sec_ch_ua = '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"'
        
        # éšæœºåŒ–å…¶ä»–å¤´éƒ¨
        accept_languages = [
            'zh-CN,zh;q=0.9,en;q=0.8',
            'zh-CN,zh;q=0.9,en;q=0.8,zh-TW;q=0.7',
            'zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7',
            'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2'
        ]
        
        platforms = ['"Windows"', '"macOS"', '"Linux"']
        
        # åŸºç¡€å¤´éƒ¨
        headers = {
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': random.choice(accept_languages),
            'Accept-Encoding': 'gzip, deflate, br',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'Cookie': self.cookie,
            'Host': 'api.zsxq.com',
            'Origin': 'https://wx.zsxq.com',
            'Pragma': 'no-cache',
            'Referer': f'https://wx.zsxq.com/dweb2/index/group/{self.group_id}',
            'Sec-Ch-Ua': sec_ch_ua,
            'Sec-Ch-Ua-Mobile': '?0',
            'Sec-Ch-Ua-Platform': random.choice(platforms),
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-site',
            'User-Agent': selected_ua
        }
        
        # éšæœºæ·»åŠ å¯é€‰å¤´éƒ¨
        optional_headers = {
            'DNT': '1',
            'Sec-GPC': '1',
            'Upgrade-Insecure-Requests': '1',
            'X-Requested-With': 'XMLHttpRequest'
        }
        
        for key, value in optional_headers.items():
            if random.random() > 0.5:  # 50%æ¦‚ç‡æ·»åŠ 
                headers[key] = value
        
        # éšæœºè°ƒæ•´æ—¶é—´æˆ³ç›¸å…³å¤´éƒ¨
        if random.random() > 0.7:  # 30%æ¦‚ç‡æ·»åŠ 
            headers['X-Timestamp'] = str(int(time.time()) + random.randint(-30, 30))
        
        if random.random() > 0.6:  # 40%æ¦‚ç‡æ·»åŠ 
            headers['X-Request-Id'] = f"req-{random.randint(100000000000, 999999999999)}"
        
        return headers
    
    def smart_delay(self):
        """æ™ºèƒ½å»¶è¿Ÿ"""
        delay = random.uniform(self.min_delay, self.max_delay)
        if self.debug_mode:
            print(f"   â±ï¸ å»¶è¿Ÿ {delay:.1f}ç§’")
        time.sleep(delay)
    
    def download_delay(self):
        """ä¸‹è½½é—´éš”å»¶è¿Ÿï¼ˆ1-3åˆ†é’Ÿï¼‰"""
        delay = random.uniform(self.download_interval_min, self.download_interval_max)
        start_time = datetime.datetime.now()
        end_time = start_time + datetime.timedelta(seconds=delay)
        
        print(f"â³ ä¸‹è½½é—´éš”: {delay:.0f}ç§’ ({delay/60:.1f}åˆ†é’Ÿ)")
        print(f"   â° å¼€å§‹æ—¶é—´: {start_time.strftime('%H:%M:%S')}")
        print(f"   ğŸ• é¢„è®¡æ¢å¤: {end_time.strftime('%H:%M:%S')}")
        
        time.sleep(delay)
        
        actual_end_time = datetime.datetime.now()
        print(f"   ğŸ• å®é™…ç»“æŸ: {actual_end_time.strftime('%H:%M:%S')}")
    
    def check_long_delay(self):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦é•¿ä¼‘çœ """
        if self.download_count > 0 and self.download_count % self.long_delay_interval == 0:
            delay = random.uniform(self.long_delay_min, self.long_delay_max)
            start_time = datetime.datetime.now()
            end_time = start_time + datetime.timedelta(seconds=delay)
            
            print(f"ğŸ›Œ é•¿ä¼‘çœ å¼€å§‹: {delay:.0f}ç§’ ({delay/60:.1f}åˆ†é’Ÿ)")
            print(f"   å·²ä¸‹è½½ {self.download_count} ä¸ªæ–‡ä»¶ï¼Œè¿›å…¥é•¿ä¼‘çœ æ¨¡å¼...")
            print(f"   â° å¼€å§‹æ—¶é—´: {start_time.strftime('%H:%M:%S')}")
            print(f"   ğŸ• é¢„è®¡æ¢å¤: {end_time.strftime('%H:%M:%S')}")
            
            time.sleep(delay)
            
            actual_end_time = datetime.datetime.now()
            print(f"ğŸ˜´ é•¿ä¼‘çœ ç»“æŸï¼Œç»§ç»­ä¸‹è½½...")
            print(f"   ğŸ• å®é™…ç»“æŸ: {actual_end_time.strftime('%H:%M:%S')}")
    
    def fetch_file_list(self, count: int = 20, index: Optional[str] = None, sort: str = "by_download_count") -> Optional[Dict[str, Any]]:
        """è·å–æ–‡ä»¶åˆ—è¡¨ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        url = f"{self.base_url}/v2/groups/{self.group_id}/files"
        max_retries = 10
        
        params = {
            "count": str(count),
            "sort": sort
        }
        
        if index:
            params["index"] = index
        
        print(f"ğŸŒ è·å–æ–‡ä»¶åˆ—è¡¨")
        print(f"   ğŸ“Š å‚æ•°: count={count}, sort={sort}")
        if index:
            print(f"   ğŸ“‘ ç´¢å¼•: {index}")
        print(f"   ğŸŒ è¯·æ±‚URL: {url}")
        
        for attempt in range(max_retries):
            if attempt > 0:
                # é‡è¯•å»¶è¿Ÿï¼š15-30ç§’
                retry_delay = random.uniform(15, 30)
                print(f"   ğŸ”„ ç¬¬{attempt}æ¬¡é‡è¯•ï¼Œç­‰å¾…{retry_delay:.1f}ç§’...")
                time.sleep(retry_delay)
            
            # æ¯æ¬¡é‡è¯•éƒ½è·å–æ–°çš„è¯·æ±‚å¤´ï¼ˆåŒ…å«æ–°çš„User-Agentç­‰ï¼‰
            self.smart_delay()
            self.request_count += 1
            headers = self.get_stealth_headers()
            
            if attempt > 0:
                print(f"   ğŸ”„ é‡è¯•#{attempt}: ä½¿ç”¨æ–°çš„User-Agent: {headers.get('User-Agent', 'N/A')[:50]}...")
            
            try:
                response = self.session.get(url, headers=headers, params=params, timeout=30)
                
                print(f"   ğŸ“Š å“åº”çŠ¶æ€: {response.status_code}")
                
                if response.status_code == 200:
                    try:
                        data = response.json()
                        
                        # åªåœ¨ç¬¬ä¸€æ¬¡å°è¯•æˆ–æœ€åä¸€æ¬¡å¤±è´¥æ—¶æ˜¾ç¤ºå®Œæ•´å“åº”
                        if attempt == 0 or attempt == max_retries - 1 or data.get('succeeded'):
                            print(f"   ğŸ“‹ å“åº”å†…å®¹: {json.dumps(data, ensure_ascii=False, indent=2)}")
                        
                        if data.get('succeeded'):
                            files = data.get('resp_data', {}).get('files', [])
                            next_index = data.get('resp_data', {}).get('index')
                            if attempt > 0:
                                print(f"   âœ… é‡è¯•æˆåŠŸï¼ç¬¬{attempt}æ¬¡é‡è¯•è·å–åˆ°æ–‡ä»¶åˆ—è¡¨")
                            else:
                                print(f"   âœ… è·å–æˆåŠŸ: {len(files)}ä¸ªæ–‡ä»¶")
                            return data
                        else:
                            error_msg = data.get('message', data.get('error', 'æœªçŸ¥é”™è¯¯'))
                            error_code = data.get('code', 'N/A')
                            print(f"   âŒ APIè¿”å›å¤±è´¥: {error_msg} (ä»£ç : {error_code})")
                            
                            # æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„é”™è¯¯
                            if error_code in [1059, 500, 502, 503, 504]:  # å†…éƒ¨é”™è¯¯ã€æœåŠ¡å™¨é”™è¯¯ç­‰
                                if attempt < max_retries - 1:
                                    print(f"   ğŸ”„ æ£€æµ‹åˆ°å¯é‡è¯•é”™è¯¯ï¼Œå‡†å¤‡é‡è¯•...")
                                    continue
                            else:
                                print(f"   ğŸš« éå¯é‡è¯•é”™è¯¯ï¼Œåœæ­¢é‡è¯•")
                                return None
                                
                    except json.JSONDecodeError as e:
                        print(f"   âŒ JSONè§£æå¤±è´¥: {e}")
                        print(f"   ğŸ“„ åŸå§‹å“åº”: {response.text[:500]}...")
                        if attempt < max_retries - 1:
                            print(f"   ğŸ”„ JSONè§£æå¤±è´¥ï¼Œå‡†å¤‡é‡è¯•...")
                            continue
                        
                elif response.status_code in [429, 500, 502, 503, 504]:  # é¢‘ç‡é™åˆ¶æˆ–æœåŠ¡å™¨é”™è¯¯
                    print(f"   âŒ HTTPé”™è¯¯: {response.status_code}")
                    print(f"   ğŸ“„ å“åº”å†…å®¹: {response.text[:200]}...")
                    if attempt < max_retries - 1:
                        print(f"   ğŸ”„ æœåŠ¡å™¨é”™è¯¯ï¼Œå‡†å¤‡é‡è¯•...")
                        continue
                else:
                    print(f"   âŒ HTTPé”™è¯¯: {response.status_code}")
                    print(f"   ğŸ“„ å“åº”å†…å®¹: {response.text[:200]}...")
                    print(f"   ğŸš« éå¯é‡è¯•HTTPé”™è¯¯ï¼Œåœæ­¢é‡è¯•")
                    return None
                    
            except Exception as e:
                print(f"   âŒ è¯·æ±‚å¼‚å¸¸: {e}")
                if attempt < max_retries - 1:
                    print(f"   ğŸ”„ è¯·æ±‚å¼‚å¸¸ï¼Œå‡†å¤‡é‡è¯•...")
                    continue
        
        print(f"   ğŸš« å·²é‡è¯•{max_retries}æ¬¡ï¼Œå…¨éƒ¨å¤±è´¥")
        return None
    
    def get_download_url(self, file_id: int) -> Optional[str]:
        """è·å–æ–‡ä»¶ä¸‹è½½é“¾æ¥ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        æ³¨æ„ï¼šfile_id å‚æ•°åœ¨ä¸åŒåœºæ™¯ä¸‹å«ä¹‰ä¸åŒï¼š
        - è¾¹è·å–è¾¹ä¸‹è½½æ—¶ï¼šä¼ å…¥çš„æ˜¯çœŸå®çš„ file_id
        - ä»æ•°æ®åº“ä¸‹è½½æ—¶ï¼šä¼ å…¥çš„æ˜¯ topic_id
        """
        url = f"{self.base_url}/v2/files/{file_id}/download_url"
        max_retries = 10
        
        print(f"   ğŸ”— è·å–ä¸‹è½½é“¾æ¥: ID={file_id}")
        print(f"   ğŸŒ è¯·æ±‚URL: {url}")
        
        for attempt in range(max_retries):
            if attempt > 0:
                # é‡è¯•å»¶è¿Ÿï¼š15-30ç§’
                retry_delay = random.uniform(15, 30)
                print(f"   ğŸ”„ ç¬¬{attempt}æ¬¡é‡è¯•ï¼Œç­‰å¾…{retry_delay:.1f}ç§’...")
                time.sleep(retry_delay)
            
            # æ¯æ¬¡é‡è¯•éƒ½è·å–æ–°çš„è¯·æ±‚å¤´ï¼ˆåŒ…å«æ–°çš„User-Agentç­‰ï¼‰
            self.smart_delay()
            self.request_count += 1
            headers = self.get_stealth_headers()
            
            if attempt > 0:
                print(f"   ğŸ”„ é‡è¯•#{attempt}: ä½¿ç”¨æ–°çš„User-Agent: {headers.get('User-Agent', 'N/A')[:50]}...")
            
            try:
                response = self.session.get(url, headers=headers, timeout=30)
                
                print(f"   ğŸ“Š å“åº”çŠ¶æ€: {response.status_code}")
                
                if response.status_code == 200:
                    try:
                        data = response.json()
                        
                        # åªåœ¨ç¬¬ä¸€æ¬¡å°è¯•æˆ–æœ€åä¸€æ¬¡å¤±è´¥æ—¶æ˜¾ç¤ºå®Œæ•´å“åº”
                        if attempt == 0 or attempt == max_retries - 1 or data.get('succeeded'):
                            print(f"   ğŸ“‹ å“åº”å†…å®¹: {json.dumps(data, ensure_ascii=False, indent=2)}")
                        
                        if data.get('succeeded'):
                            download_url = data.get('resp_data', {}).get('download_url')
                            if download_url:
                                if attempt > 0:
                                    print(f"   âœ… é‡è¯•æˆåŠŸï¼ç¬¬{attempt}æ¬¡é‡è¯•è·å–åˆ°ä¸‹è½½é“¾æ¥")
                                else:
                                    print(f"   âœ… è·å–ä¸‹è½½é“¾æ¥æˆåŠŸ")
                                return download_url
                            else:
                                print(f"   âŒ å“åº”ä¸­æ— ä¸‹è½½é“¾æ¥å­—æ®µ")
                        else:
                            error_msg = data.get('message', data.get('error', 'æœªçŸ¥é”™è¯¯'))
                            error_code = data.get('code', 'N/A')
                            print(f"   âŒ APIè¿”å›å¤±è´¥: {error_msg} (ä»£ç : {error_code})")
                            
                            # æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„é”™è¯¯
                            if error_code in [1059, 500, 502, 503, 504]:  # å†…éƒ¨é”™è¯¯ã€æœåŠ¡å™¨é”™è¯¯ç­‰
                                if attempt < max_retries - 1:
                                    print(f"   ğŸ”„ æ£€æµ‹åˆ°å¯é‡è¯•é”™è¯¯ï¼Œå‡†å¤‡é‡è¯•...")
                                    continue
                            else:
                                print(f"   ğŸš« éå¯é‡è¯•é”™è¯¯ï¼Œåœæ­¢é‡è¯•")
                                return None
                                
                    except json.JSONDecodeError as e:
                        print(f"   âŒ JSONè§£æå¤±è´¥: {e}")
                        print(f"   ğŸ“„ åŸå§‹å“åº”: {response.text[:500]}...")
                        if attempt < max_retries - 1:
                            print(f"   ğŸ”„ JSONè§£æå¤±è´¥ï¼Œå‡†å¤‡é‡è¯•...")
                            continue
                        
                elif response.status_code in [429, 500, 502, 503, 504]:  # é¢‘ç‡é™åˆ¶æˆ–æœåŠ¡å™¨é”™è¯¯
                    print(f"   âŒ HTTPé”™è¯¯: {response.status_code}")
                    print(f"   ğŸ“„ å“åº”å†…å®¹: {response.text[:200]}...")
                    if attempt < max_retries - 1:
                        print(f"   ğŸ”„ æœåŠ¡å™¨é”™è¯¯ï¼Œå‡†å¤‡é‡è¯•...")
                        continue
                else:
                    print(f"   âŒ HTTPé”™è¯¯: {response.status_code}")
                    print(f"   ğŸ“„ å“åº”å†…å®¹: {response.text[:200]}...")
                    print(f"   ğŸš« éå¯é‡è¯•HTTPé”™è¯¯ï¼Œåœæ­¢é‡è¯•")
                    return None
                    
            except Exception as e:
                print(f"   âŒ è¯·æ±‚å¼‚å¸¸: {e}")
                if attempt < max_retries - 1:
                    print(f"   ğŸ”„ è¯·æ±‚å¼‚å¸¸ï¼Œå‡†å¤‡é‡è¯•...")
                    continue
        
        print(f"   ğŸš« å·²é‡è¯•{max_retries}æ¬¡ï¼Œå…¨éƒ¨å¤±è´¥")
        return None
    
    def download_file(self, file_info: Dict[str, Any]) -> bool:
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
        file_data = file_info.get('file', {})
        file_id = file_data.get('id')
        file_name = file_data.get('name', 'Unknown')
        file_size = file_data.get('size', 0)
        download_count = file_data.get('download_count', 0)
        
        print(f"ğŸ“¥ å‡†å¤‡ä¸‹è½½æ–‡ä»¶:")
        print(f"   ğŸ“„ åç§°: {file_name}")
        print(f"   ğŸ“Š å¤§å°: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)")
        print(f"   ğŸ“ˆ ä¸‹è½½æ¬¡æ•°: {download_count}")
        
        # æ¸…ç†æ–‡ä»¶åï¼ˆç§»é™¤éæ³•å­—ç¬¦ï¼‰
        safe_filename = "".join(c for c in file_name if c.isalnum() or c in '._-ï¼ˆï¼‰()[]{}')
        if not safe_filename:
            safe_filename = f"file_{file_id}"
        
        file_path = os.path.join(self.download_dir, safe_filename)
        
        # ğŸš€ ä¼˜åŒ–ï¼šå…ˆæ£€æŸ¥æœ¬åœ°æ–‡ä»¶ï¼Œé¿å…æ— æ„ä¹‰çš„APIè¯·æ±‚
        if os.path.exists(file_path):
            existing_size = os.path.getsize(file_path)
            if existing_size == file_size:
                print(f"   âœ… æ–‡ä»¶å·²å­˜åœ¨ä¸”å¤§å°åŒ¹é…ï¼Œè·³è¿‡ä¸‹è½½")
                return "skipped"  # è¿”å›ç‰¹æ®Šå€¼è¡¨ç¤ºè·³è¿‡
            else:
                print(f"   âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ä½†å¤§å°ä¸åŒ¹é…ï¼Œé‡æ–°ä¸‹è½½")
        
        # åªæœ‰åœ¨éœ€è¦ä¸‹è½½æ—¶æ‰è·å–ä¸‹è½½é“¾æ¥
        download_url = self.get_download_url(file_id)
        if not download_url:
            print(f"   âŒ æ— æ³•è·å–ä¸‹è½½é“¾æ¥")
            return False
        
        try:
            # ä¸‹è½½æ–‡ä»¶
            print(f"   ğŸš€ å¼€å§‹ä¸‹è½½...")
            response = self.session.get(download_url, timeout=300, stream=True)
            
            if response.status_code == 200:
                total_size = int(response.headers.get('content-length', 0))
                downloaded_size = 0
                
                with open(file_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded_size += len(chunk)
                            
                            # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯10MBæ˜¾ç¤ºä¸€æ¬¡ï¼‰
                            if downloaded_size % (10 * 1024 * 1024) == 0 or downloaded_size == total_size:
                                if total_size > 0:
                                    progress = (downloaded_size / total_size) * 100
                                    print(f"   ğŸ“Š è¿›åº¦: {progress:.1f}% ({downloaded_size:,}/{total_size:,} bytes)")
                                else:
                                    print(f"   ğŸ“Š å·²ä¸‹è½½: {downloaded_size:,} bytes")
                
                # éªŒè¯æ–‡ä»¶å¤§å°
                final_size = os.path.getsize(file_path)
                if file_size > 0 and final_size != file_size:
                    print(f"   âš ï¸ æ–‡ä»¶å¤§å°ä¸åŒ¹é…: é¢„æœŸ{file_size:,}, å®é™…{final_size:,}")
                
                print(f"   âœ… ä¸‹è½½å®Œæˆ: {safe_filename}")
                print(f"   ğŸ’¾ ä¿å­˜è·¯å¾„: {file_path}")
                
                self.download_count += 1
                return True
            else:
                print(f"   âŒ ä¸‹è½½å¤±è´¥: HTTP {response.status_code}")
                return False
                
        except Exception as e:
            print(f"   âŒ ä¸‹è½½å¼‚å¸¸: {e}")
            if os.path.exists(file_path):
                os.remove(file_path)
                print(f"   ğŸ—‘ï¸ åˆ é™¤ä¸å®Œæ•´æ–‡ä»¶")
            return False
    
    def download_files_batch(self, max_files: Optional[int] = None, start_index: Optional[str] = None) -> Dict[str, int]:
        """æ‰¹é‡ä¸‹è½½æ–‡ä»¶"""
        if max_files is None:
            print(f"\nğŸ“¥ å¼€å§‹æ— é™ä¸‹è½½æ–‡ä»¶ (ç›´åˆ°æ²¡æœ‰æ›´å¤šæ–‡ä»¶)")
        else:
            print(f"\nğŸ“¥ å¼€å§‹æ‰¹é‡ä¸‹è½½æ–‡ä»¶ (æœ€å¤š{max_files}ä¸ª)")
        
        stats = {'total_files': 0, 'downloaded': 0, 'skipped': 0, 'failed': 0}
        current_index = start_index
        downloaded_in_batch = 0
        
        while max_files is None or downloaded_in_batch < max_files:
            # è·å–æ–‡ä»¶åˆ—è¡¨
            data = self.fetch_file_list(count=20, index=current_index)
            if not data:
                print("âŒ è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥")
                break
            
            files = data.get('resp_data', {}).get('files', [])
            next_index = data.get('resp_data', {}).get('index')
            
            if not files:
                print("ğŸ“­ æ²¡æœ‰æ›´å¤šæ–‡ä»¶")
                break
            
            print(f"\nğŸ“‹ å½“å‰æ‰¹æ¬¡: {len(files)} ä¸ªæ–‡ä»¶")
            
            for i, file_info in enumerate(files):
                if max_files is not None and downloaded_in_batch >= max_files:
                    break
                
                file_data = file_info.get('file', {})
                file_name = file_data.get('name', 'Unknown')
                
                if max_files is None:
                    print(f"\nã€ç¬¬{downloaded_in_batch + 1}ä¸ªæ–‡ä»¶ã€‘{file_name}")
                else:
                    print(f"\nã€{downloaded_in_batch + 1}/{max_files}ã€‘{file_name}")
                
                # ä¸‹è½½æ–‡ä»¶
                result = self.download_file(file_info)
                
                if result == "skipped":
                    stats['skipped'] += 1
                    print(f"   âš ï¸ æ–‡ä»¶å·²è·³è¿‡ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª")
                elif result:
                    stats['downloaded'] += 1
                    downloaded_in_batch += 1
                    
                    # æ£€æŸ¥é•¿ä¼‘çœ 
                    self.check_long_delay()
                    
                    # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªæ–‡ä»¶ï¼Œè¿›è¡Œä¸‹è½½é—´éš”
                    has_more_in_batch = (i + 1) < len(files)
                    not_reached_limit = max_files is None or downloaded_in_batch < max_files
                    if has_more_in_batch and not_reached_limit:
                        self.download_delay()
                else:
                    stats['failed'] += 1
                
                stats['total_files'] += 1
            
            # å‡†å¤‡ä¸‹ä¸€é¡µ
            should_continue = max_files is None or downloaded_in_batch < max_files
            if next_index and should_continue:
                current_index = next_index
                print(f"\nğŸ“„ å‡†å¤‡è·å–ä¸‹ä¸€é¡µ: {next_index}")
                time.sleep(2)  # é¡µé¢é—´çŸ­æš‚å»¶è¿Ÿ
            else:
                break
        
        print(f"\nğŸ‰ æ‰¹é‡ä¸‹è½½å®Œæˆ:")
        print(f"   ğŸ“Š æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
        print(f"   âœ… ä¸‹è½½æˆåŠŸ: {stats['downloaded']}")
        print(f"   âš ï¸ è·³è¿‡: {stats['skipped']}")
        print(f"   âŒ å¤±è´¥: {stats['failed']}")
        
        return stats
    
    def show_file_list(self, count: int = 20, index: Optional[str] = None) -> Optional[str]:
        """æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨"""
        data = self.fetch_file_list(count=count, index=index)
        if not data:
            return None
        
        files = data.get('resp_data', {}).get('files', [])
        next_index = data.get('resp_data', {}).get('index')
        
        print(f"\nğŸ“‹ æ–‡ä»¶åˆ—è¡¨ ({len(files)} ä¸ªæ–‡ä»¶):")
        print("="*80)
        
        for i, file_info in enumerate(files, 1):
            file_data = file_info.get('file', {})
            topic_data = file_info.get('topic', {})
            
            file_name = file_data.get('name', 'Unknown')
            file_size = file_data.get('size', 0)
            download_count = file_data.get('download_count', 0)
            create_time = file_data.get('create_time', 'Unknown')
            
            topic_title = topic_data.get('talk', {}).get('text', '')[:50] if topic_data.get('talk') else ''
            
            print(f"{i:2d}. ğŸ“„ {file_name}")
            print(f"    ğŸ“Š å¤§å°: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)")
            print(f"    ğŸ“ˆ ä¸‹è½½: {download_count} æ¬¡")
            print(f"    â° æ—¶é—´: {create_time}")
            if topic_title:
                print(f"    ğŸ’¬ è¯é¢˜: {topic_title}...")
            print()
        
        if next_index:
            print(f"ğŸ“‘ ä¸‹ä¸€é¡µç´¢å¼•: {next_index}")
        else:
            print("ğŸ“­ æ²¡æœ‰æ›´å¤šæ–‡ä»¶")
        
        return next_index
    
    def collect_all_files_to_database(self) -> Dict[str, int]:
        """æ”¶é›†æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯åˆ°æ•°æ®åº“"""
        print(f"\nğŸ“Š å¼€å§‹æ”¶é›†æ–‡ä»¶åˆ—è¡¨åˆ°æ•°æ®åº“...")
        
        # åˆ›å»ºæ”¶é›†è®°å½•
        self.file_db.cursor.execute("INSERT INTO collection_log (start_time) VALUES (?)", 
                      (datetime.datetime.now().isoformat(),))
        log_id = self.file_db.cursor.lastrowid
        self.file_db.conn.commit()
        
        stats = {'total_files': 0, 'new_files': 0, 'skipped_files': 0}
        current_index = None
        page_count = 0
        
        try:
            while True:
                page_count += 1
                print(f"\nğŸ“„ æ”¶é›†ç¬¬{page_count}é¡µæ–‡ä»¶åˆ—è¡¨...")
                
                # è·å–æ–‡ä»¶åˆ—è¡¨
                data = self.fetch_file_list(count=20, index=current_index)
                if not data:
                    print(f"âŒ ç¬¬{page_count}é¡µè·å–å¤±è´¥ï¼Œæ”¶é›†è¿‡ç¨‹ä¸­æ–­")
                    print(f"ğŸ’¾ å·²æˆåŠŸæ”¶é›†å‰{page_count-1}é¡µçš„æ•°æ®")
                    break
                
                files = data.get('resp_data', {}).get('files', [])
                next_index = data.get('resp_data', {}).get('index')
                
                if not files:
                    print("ğŸ“­ æ²¡æœ‰æ›´å¤šæ–‡ä»¶")
                    break
                
                print(f"   ğŸ“‹ å½“å‰é¡µé¢: {len(files)} ä¸ªæ–‡ä»¶")
                
                # ä½¿ç”¨å®Œæ•´æ•°æ®åº“å¯¼å…¥æ•´ä¸ªAPIå“åº”
                try:
                    page_stats = self.file_db.import_file_response(data)
                    
                    stats['new_files'] += page_stats.get('files', 0)
                    stats['total_files'] += len(files)
                    
                    print(f"      âœ… æ–°å¢æ–‡ä»¶: {page_stats.get('files', 0)}")
                    print(f"      ğŸ“Š å…¶ä»–æ•°æ®: è¯é¢˜+{page_stats.get('topics', 0)}, ç”¨æˆ·+{page_stats.get('users', 0)}")
                    
                except Exception as e:
                    print(f"   âŒ ç¬¬{page_count}é¡µå­˜å‚¨å¤±è´¥: {e}")
                    continue
                
                print(f"   âœ… ç¬¬{page_count}é¡µå­˜å‚¨å®Œæˆ")
                
                # å‡†å¤‡ä¸‹ä¸€é¡µ
                if next_index:
                    current_index = next_index
                    # é¡µé¢é—´çŸ­æš‚å»¶è¿Ÿ
                    time.sleep(random.uniform(2, 5))
                else:
                    break
                    
        except KeyboardInterrupt:
            print(f"\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ”¶é›†")
        except Exception as e:
            print(f"\nâŒ æ”¶é›†è¿‡ç¨‹å¼‚å¸¸: {e}")
        
        # æ›´æ–°æ”¶é›†è®°å½•
        self.file_db.cursor.execute('''
            UPDATE collection_log SET 
                end_time = ?, total_files = ?, new_files = ?, status = 'completed'
            WHERE id = ?
        ''', (datetime.datetime.now().isoformat(), stats['total_files'], 
              stats['new_files'], log_id))
        self.file_db.conn.commit()
        
        print(f"\nğŸ‰ æ–‡ä»¶åˆ—è¡¨æ”¶é›†å®Œæˆ:")
        print(f"   ğŸ“Š å¤„ç†æ–‡ä»¶æ•°: {stats['total_files']}")
        print(f"   âœ… æ–°å¢æ–‡ä»¶: {stats['new_files']}")
        print(f"   âš ï¸ è·³è¿‡é‡å¤: {stats.get('skipped_files', 0)}")
        print(f"   ğŸ“„ æ”¶é›†é¡µæ•°: {page_count}")
        
        return stats
    
    def get_database_time_range(self) -> Dict[str, Any]:
        """è·å–å®Œæ•´æ•°æ®åº“ä¸­æ–‡ä»¶çš„æ—¶é—´èŒƒå›´ä¿¡æ¯"""
        # ä½¿ç”¨æ–°æ•°æ®åº“æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        stats = self.file_db.get_database_stats()
        total_files = stats.get('files', 0)
        
        if total_files == 0:
            return {'has_data': False, 'total_files': 0}
        
        # è·å–æ—¶é—´èŒƒå›´
        self.file_db.cursor.execute('''
            SELECT MIN(create_time) as oldest_time, 
                   MAX(create_time) as newest_time,
                   COUNT(*) as total_count
            FROM files 
            WHERE create_time IS NOT NULL AND create_time != ''
        ''')
        
        result = self.file_db.cursor.fetchone()
        
        return {
            'has_data': True,
            'total_files': total_files,
            'oldest_time': result[0] if result else None,
            'newest_time': result[1] if result else None,
            'time_based_count': result[2] if result else 0
        }
    
    def collect_files_by_time(self, sort: str = "by_create_time", start_time: Optional[str] = None) -> Dict[str, int]:
        """æŒ‰æ—¶é—´é¡ºåºæ”¶é›†æ–‡ä»¶åˆ—è¡¨åˆ°æ•°æ®åº“ï¼ˆä½¿ç”¨å®Œæ•´çš„æ•°æ®åº“ç»“æ„ï¼‰"""
        print(f"\nğŸ“Š å¼€å§‹æŒ‰æ—¶é—´é¡ºåºæ”¶é›†æ–‡ä»¶åˆ—è¡¨åˆ°å®Œæ•´æ•°æ®åº“...")
        print(f"   ğŸ“… æ’åºæ–¹å¼: {sort}")
        if start_time:
            print(f"   â° èµ·å§‹æ—¶é—´: {start_time}")
        
        # ä½¿ç”¨å®Œæ•´æ•°æ®åº“çš„ç»Ÿè®¡ä¿¡æ¯
        initial_stats = self.file_db.get_database_stats()
        initial_files = initial_stats.get('files', 0)
        print(f"   ğŸ“Š æ•°æ®åº“åˆå§‹çŠ¶æ€: {initial_files} ä¸ªæ–‡ä»¶")
        
        total_imported_stats = {
            'files': 0, 'topics': 0, 'users': 0, 'groups': 0,
            'images': 0, 'comments': 0, 'likes': 0, 'columns': 0, 'solutions': 0
        }
        current_index = start_time  # ä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºindex
        page_count = 0
        
        try:
            while True:
                page_count += 1
                print(f"\nğŸ“„ æ”¶é›†ç¬¬{page_count}é¡µæ–‡ä»¶åˆ—è¡¨...")
                
                # è·å–æ–‡ä»¶åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰
                data = self.fetch_file_list(count=20, index=current_index, sort=sort)
                if not data:
                    print(f"âŒ ç¬¬{page_count}é¡µè·å–å¤±è´¥ï¼Œæ”¶é›†è¿‡ç¨‹ä¸­æ–­")
                    print(f"ğŸ’¾ å·²æˆåŠŸæ”¶é›†å‰{page_count-1}é¡µçš„æ•°æ®")
                    break
                
                files = data.get('resp_data', {}).get('files', [])
                next_index = data.get('resp_data', {}).get('index')
                
                if not files:
                    print("ğŸ“­ æ²¡æœ‰æ›´å¤šæ–‡ä»¶")
                    break
                
                print(f"   ğŸ“‹ å½“å‰é¡µé¢: {len(files)} ä¸ªæ–‡ä»¶")
                
                # ä½¿ç”¨å®Œæ•´æ•°æ®åº“å¯¼å…¥æ•´ä¸ªAPIå“åº”
                try:
                    page_stats = self.file_db.import_file_response(data)
                    
                    # ç´¯è®¡ç»Ÿè®¡
                    for key in total_imported_stats:
                        total_imported_stats[key] += page_stats.get(key, 0)
                    
                    print(f"   âœ… ç¬¬{page_count}é¡µå­˜å‚¨å®Œæˆ: æ–‡ä»¶+{page_stats.get('files', 0)}, è¯é¢˜+{page_stats.get('topics', 0)}")
                    print(f"      ç”¨æˆ·+{page_stats.get('users', 0)}, ç¾¤ç»„+{page_stats.get('groups', 0)}, å›¾ç‰‡+{page_stats.get('images', 0)}")
                    
                except Exception as e:
                    print(f"   âŒ ç¬¬{page_count}é¡µå­˜å‚¨å¤±è´¥: {e}")
                    continue
                
                # å‡†å¤‡ä¸‹ä¸€é¡µ
                if next_index:
                    current_index = next_index
                    print(f"   â­ï¸ ä¸‹ä¸€é¡µæ—¶é—´æˆ³: {current_index}")
                    # é¡µé¢é—´çŸ­æš‚å»¶è¿Ÿ
                    time.sleep(random.uniform(2, 5))
                else:
                    print("ğŸ“­ å·²åˆ°è¾¾æœ€åä¸€é¡µ")
                    break
                    
        except KeyboardInterrupt:
            print(f"\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ”¶é›†")
        except Exception as e:
            print(f"\nâŒ æ”¶é›†è¿‡ç¨‹å¼‚å¸¸: {e}")
        
        # æœ€ç»ˆç»Ÿè®¡
        final_stats = self.file_db.get_database_stats()
        final_files = final_stats.get('files', 0)
        new_files = final_files - initial_files
        
        print(f"\nğŸ‰ å®Œæ•´æ–‡ä»¶åˆ—è¡¨æ”¶é›†å®Œæˆ:")
        print(f"   ğŸ“Š å¤„ç†é¡µæ•°: {page_count}")
        print(f"   ğŸ“ æ–°å¢æ–‡ä»¶: {new_files} (æ€»è®¡: {final_files})")
        print(f"   ğŸ“‹ ç´¯è®¡å¯¼å…¥ç»Ÿè®¡:")
        for key, value in total_imported_stats.items():
            if value > 0:
                print(f"      {key}: +{value}")
        
        print(f"\nğŸ“Š å½“å‰æ•°æ®åº“çŠ¶æ€:")
        for table, count in final_stats.items():
            if count > 0:
                print(f"   {table}: {count}")
        
        return {
            'total_files': final_files,
            'new_files': new_files,
            'pages': page_count,
            **total_imported_stats
        }
    
    def collect_incremental_files(self) -> Dict[str, int]:
        """å¢é‡æ”¶é›†ï¼šä»æ•°æ®åº“æœ€è€æ—¶é—´æˆ³å¼€å§‹ç»§ç»­æ”¶é›†"""
        print(f"\nğŸ”„ å¼€å§‹å¢é‡æ–‡ä»¶æ”¶é›†...")
        
        # è·å–æ•°æ®åº“æ—¶é—´èŒƒå›´
        time_info = self.get_database_time_range()
        
        if not time_info['has_data']:
            print("ğŸ“Š æ•°æ®åº“ä¸ºç©ºï¼Œå°†è¿›è¡Œå…¨é‡æ”¶é›†")
            return self.collect_files_by_time()
        
        oldest_time = time_info['oldest_time']
        newest_time = time_info['newest_time']
        total_files = time_info['total_files']
        
        print(f"ğŸ“Š æ•°æ®åº“ç°çŠ¶:")
        print(f"   ç°æœ‰æ–‡ä»¶æ•°: {total_files}")
        print(f"   æœ€è€æ—¶é—´: {oldest_time}")
        print(f"   æœ€æ–°æ—¶é—´: {newest_time}")
        
        if not oldest_time:
            print("âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰æœ‰æ•ˆçš„æ—¶é—´ä¿¡æ¯ï¼Œè¿›è¡Œå…¨é‡æ”¶é›†")
            return self.collect_files_by_time()
        
        # ä»æœ€è€æ—¶é—´æˆ³å¼€å§‹æ”¶é›†æ›´æ—©çš„æ–‡ä»¶
        print(f"ğŸ¯ å°†ä»æœ€è€æ—¶é—´æˆ³å¼€å§‹æ”¶é›†æ›´æ—©çš„æ–‡ä»¶...")
        
        # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºæ¯«ç§’æ•°ç”¨ä½œindex
        try:
            if '+' in oldest_time:
                # å¤„ç†å¸¦æ—¶åŒºçš„æ—¶é—´æˆ³
                from datetime import datetime
                dt = datetime.fromisoformat(oldest_time.replace('+0800', '+08:00'))
                timestamp_ms = int(dt.timestamp() * 1000)
            else:
                # å¦‚æœå·²ç»æ˜¯æ¯«ç§’æ—¶é—´æˆ³
                timestamp_ms = int(oldest_time)
            
            start_index = str(timestamp_ms)
            print(f"ğŸš€ å¢é‡æ”¶é›†èµ·å§‹æ—¶é—´æˆ³: {start_index}")
            
            return self.collect_files_by_time(start_time=start_index)
            
        except Exception as e:
            print(f"âš ï¸ æ—¶é—´æˆ³å¤„ç†å¤±è´¥: {e}")
            print("ğŸ”„ æ”¹ä¸ºå…¨é‡æ”¶é›†")
            return self.collect_files_by_time()
    
    def download_files_from_database(self, max_files: Optional[int] = None, status_filter: str = 'pending') -> Dict[str, int]:
        """ä»å®Œæ•´æ•°æ®åº“ä¸‹è½½æ–‡ä»¶ï¼ˆä½¿ç”¨file_idå­—æ®µï¼‰"""
        print(f"\nğŸ“¥ å¼€å§‹ä»å®Œæ•´æ•°æ®åº“ä¸‹è½½æ–‡ä»¶...")
        if max_files:
            print(f"   ğŸ¯ ä¸‹è½½é™åˆ¶: {max_files}ä¸ªæ–‡ä»¶")
        print(f"   ğŸ” çŠ¶æ€ç­›é€‰: {status_filter} (æ³¨æ„: æ–°æ•°æ®åº“æš‚æ— ä¸‹è½½çŠ¶æ€ï¼Œé»˜è®¤ä¸ºpending)")
        
        # ä»å®Œæ•´æ•°æ®åº“è·å–æ–‡ä»¶åˆ—è¡¨
        if max_files:
            self.file_db.cursor.execute('''
                SELECT file_id, name, size, download_count, create_time 
                FROM files 
                ORDER BY download_count DESC, size ASC 
                LIMIT ?
            ''', (max_files,))
        else:
            self.file_db.cursor.execute('''
                SELECT file_id, name, size, download_count, create_time 
                FROM files 
                ORDER BY download_count DESC, size ASC
            ''')
        
        files_to_download = self.file_db.cursor.fetchall()
        
        if not files_to_download:
            print(f"ğŸ“­ æ•°æ®åº“ä¸­æ²¡æœ‰æ–‡ä»¶å¯ä¸‹è½½")
            return {'total_files': 0, 'downloaded': 0, 'skipped': 0, 'failed': 0}
        
        print(f"ğŸ“‹ æ‰¾åˆ° {len(files_to_download)} ä¸ªå¾…ä¸‹è½½æ–‡ä»¶")
        
        stats = {'total_files': len(files_to_download), 'downloaded': 0, 'skipped': 0, 'failed': 0}
        
        for i, (file_id, file_name, file_size, download_count, create_time) in enumerate(files_to_download, 1):
            try:
                print(f"\nã€{i}/{len(files_to_download)}ã€‘{file_name}")
                print(f"   ğŸ“Š æ–‡ä»¶ID: {file_id}, å¤§å°: {file_size/1024:.1f}KB, ä¸‹è½½æ¬¡æ•°: {download_count}")
                
                # æ„é€ æ–‡ä»¶ä¿¡æ¯ç»“æ„ï¼ˆä½¿ç”¨æ­£ç¡®çš„file_idï¼‰
                file_info = {
                    'file': {
                        'id': file_id,  # ä½¿ç”¨æ­£ç¡®çš„file_id
                        'name': file_name,
                        'size': file_size,
                        'download_count': download_count
                    }
                }
                
                # ä¸‹è½½æ–‡ä»¶
                result = self.download_file(file_info)
                
                if result == "skipped":
                    stats['skipped'] += 1
                    print(f"   âš ï¸ æ–‡ä»¶å·²è·³è¿‡")
                elif result:
                    stats['downloaded'] += 1
                    
                    # æ£€æŸ¥é•¿ä¼‘çœ 
                    self.check_long_delay()
                    
                    # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªæ–‡ä»¶ï¼Œè¿›è¡Œä¸‹è½½é—´éš”
                    if i < len(files_to_download):
                        self.download_delay()
                else:
                    stats['failed'] += 1
                    print(f"   âŒ ä¸‹è½½å¤±è´¥")
                
            except KeyboardInterrupt:
                print(f"\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
                break
            except Exception as e:
                print(f"   âŒ å¤„ç†æ–‡ä»¶å¼‚å¸¸: {e}")
                stats['failed'] += 1
                continue
        
        print(f"\nğŸ‰ æ•°æ®åº“ä¸‹è½½å®Œæˆ:")
        print(f"   ğŸ“Š æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
        print(f"   âœ… ä¸‹è½½æˆåŠŸ: {stats['downloaded']}")
        print(f"   âš ï¸ è·³è¿‡: {stats['skipped']}")
        print(f"   âŒ å¤±è´¥: {stats['failed']}")
        
        return stats
    
    def show_database_stats(self):
        """æ˜¾ç¤ºå®Œæ•´æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\nğŸ“Š å®Œæ•´æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
        print("="*60)
        print(f"ğŸ“ æ•°æ®åº“æ–‡ä»¶: {self.db_path}")
        
        # ä½¿ç”¨æ–°æ•°æ®åº“çš„ç»Ÿè®¡æ–¹æ³•
        stats = self.file_db.get_database_stats()
        
        # ä¸»è¦æ•°æ®ç»Ÿè®¡
        total_files = stats.get('files', 0)
        total_topics = stats.get('topics', 0)
        total_users = stats.get('users', 0)
        total_groups = stats.get('groups', 0)
        
        print(f"ğŸ“ˆ æ ¸å¿ƒæ•°æ®:")
        print(f"   ğŸ“„ æ–‡ä»¶æ•°é‡: {total_files:,}")
        print(f"   ğŸ’¬ è¯é¢˜æ•°é‡: {total_topics:,}")
        print(f"   ğŸ‘¥ ç”¨æˆ·æ•°é‡: {total_users:,}")
        print(f"   ğŸ  ç¾¤ç»„æ•°é‡: {total_groups:,}")
        
        # æ–‡ä»¶å¤§å°ç»Ÿè®¡
        self.file_db.cursor.execute("SELECT SUM(size) FROM files WHERE size IS NOT NULL")
        result = self.file_db.cursor.fetchone()
        total_size = result[0] if result and result[0] else 0
        
        if total_size > 0:
            print(f"ğŸ’¾ æ€»æ–‡ä»¶å¤§å°: {total_size/1024/1024:.2f} MB")
        
        # è¯¦ç»†è¡¨ç»Ÿè®¡
        print(f"\nğŸ“‹ è¯¦ç»†è¡¨ç»Ÿè®¡:")
        for table_name, count in stats.items():
            if count > 0:
                # æ·»åŠ è¡¨æƒ…ç¬¦å·
                emoji_map = {
                    'files': 'ğŸ“„', 'groups': 'ğŸ ', 'users': 'ğŸ‘¥', 'topics': 'ğŸ’¬',
                    'talks': 'ğŸ’­', 'images': 'ğŸ–¼ï¸', 'topic_files': 'ğŸ“',
                    'latest_likes': 'ğŸ‘', 'comments': 'ğŸ’¬', 'like_emojis': 'ğŸ˜Š',
                    'user_liked_emojis': 'â¤ï¸', 'columns': 'ğŸ“š', 'topic_columns': 'ğŸ”—',
                    'solutions': 'ğŸ’¡', 'solution_files': 'ğŸ“‹', 'file_topic_relations': 'ğŸ”—',
                    'api_responses': 'ğŸ“¡'
                }
                emoji = emoji_map.get(table_name, 'ğŸ“Š')
                print(f"   {emoji} {table_name}: {count:,}")
        
        # æ–‡ä»¶åˆ›å»ºæ—¶é—´èŒƒå›´
        self.file_db.cursor.execute('''
            SELECT MIN(create_time), MAX(create_time), COUNT(*) 
            FROM files 
            WHERE create_time IS NOT NULL
        ''')
        time_result = self.file_db.cursor.fetchone()
        
        if time_result and time_result[2] > 0:
            min_time, max_time, time_count = time_result
            print(f"\nâ° æ–‡ä»¶æ—¶é—´èŒƒå›´:")
            print(f"   æœ€æ—©æ–‡ä»¶: {min_time}")
            print(f"   æœ€æ–°æ–‡ä»¶: {max_time}")
            print(f"   æœ‰æ—¶é—´ä¿¡æ¯çš„æ–‡ä»¶: {time_count:,}")
        
        # APIå“åº”ç»Ÿè®¡
        self.file_db.cursor.execute('''
            SELECT succeeded, COUNT(*) 
            FROM api_responses 
            GROUP BY succeeded
        ''')
        api_stats = self.file_db.cursor.fetchall()
        
        if api_stats:
            print(f"\nğŸ“¡ APIå“åº”ç»Ÿè®¡:")
            for succeeded, count in api_stats:
                status = "æˆåŠŸ" if succeeded else "å¤±è´¥"
                emoji = "âœ…" if succeeded else "âŒ"
                print(f"   {emoji} {status}: {count:,}")
        
        print("="*60)
    
    def adjust_settings(self):
        """è°ƒæ•´ä¸‹è½½è®¾ç½®"""
        print(f"\nğŸ”§ å½“å‰ä¸‹è½½è®¾ç½®:")
        print(f"   ä¸‹è½½é—´éš”: {self.download_interval_min}-{self.download_interval_max}ç§’ ({self.download_interval_min/60:.1f}-{self.download_interval_max/60:.1f}åˆ†é’Ÿ)")
        print(f"   é•¿ä¼‘çœ é—´éš”: æ¯{self.long_delay_interval}ä¸ªæ–‡ä»¶")
        print(f"   é•¿ä¼‘çœ æ—¶é—´: {self.long_delay_min}-{self.long_delay_max}ç§’ ({self.long_delay_min/60:.1f}-{self.long_delay_max/60:.1f}åˆ†é’Ÿ)")
        print(f"   ä¸‹è½½ç›®å½•: {self.download_dir}")
        
        try:
            new_interval = int(input(f"é•¿ä¼‘çœ é—´éš” (å½“å‰æ¯{self.long_delay_interval}ä¸ªæ–‡ä»¶): ") or self.long_delay_interval)
            new_dir = input(f"ä¸‹è½½ç›®å½• (å½“å‰: {self.download_dir}): ").strip() or self.download_dir
            
            self.long_delay_interval = max(new_interval, 1)
            
            if new_dir != self.download_dir:
                self.download_dir = new_dir
                os.makedirs(new_dir, exist_ok=True)
                print(f"ğŸ“ ä¸‹è½½ç›®å½•å·²æ›´æ–°: {os.path.abspath(new_dir)}")
            
            print(f"âœ… è®¾ç½®å·²æ›´æ–°")
            
        except ValueError:
            print("âŒ è¾“å…¥æ— æ•ˆï¼Œä¿æŒåŸè®¾ç½®")
    
    def close(self):
        """å…³é—­èµ„æº"""
        if hasattr(self, 'file_db') and self.file_db:
            self.file_db.close()
            print("ğŸ”’ æ–‡ä»¶æ•°æ®åº“è¿æ¥å·²å…³é—­") 